{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022803,
     "end_time": "2020-11-24T18:45:32.316383",
     "exception": false,
     "start_time": "2020-11-24T18:45:32.293580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "** DATA SOURCE:**\n",
    "> **FOLDERS:**\n",
    "* lish-moa folder: https://www.kaggle.com/c/lish-moa\n",
    "* fold-save: in the fold-save folder in this repo\n",
    "* test-public-moa: in the test-public-moa folder in this repo\n",
    "* best-lb: in best-lb folder in this repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:45:32.366067Z",
     "iopub.status.busy": "2020-11-24T18:45:32.365077Z",
     "iopub.status.idle": "2020-11-24T18:45:33.118641Z",
     "shell.execute_reply": "2020-11-24T18:45:33.117954Z"
    },
    "papermill": {
     "duration": 0.780819,
     "end_time": "2020-11-24T18:45:33.118811",
     "exception": false,
     "start_time": "2020-11-24T18:45:32.337992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/rank-gauss\")\n",
    "from gauss_rank_scaler import GaussRankScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-24T18:45:33.172155Z",
     "iopub.status.busy": "2020-11-24T18:45:33.171282Z",
     "iopub.status.idle": "2020-11-24T18:45:34.631118Z",
     "shell.execute_reply": "2020-11-24T18:45:34.629932Z"
    },
    "papermill": {
     "duration": 1.489969,
     "end_time": "2020-11-24T18:45:34.631261",
     "exception": false,
     "start_time": "2020-11-24T18:45:33.141292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-24T18:45:34.684937Z",
     "iopub.status.busy": "2020-11-24T18:45:34.684002Z",
     "iopub.status.idle": "2020-11-24T18:45:43.497601Z",
     "shell.execute_reply": "2020-11-24T18:45:43.496251Z"
    },
    "papermill": {
     "duration": 8.844165,
     "end_time": "2020-11-24T18:45:43.497789",
     "exception": false,
     "start_time": "2020-11-24T18:45:34.653624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "drug_ids = pd.read_csv('../input/lish-moa/train_drug.csv')\n",
    "train_targets_noscore = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "folds = np.load('../input/fold-save/folds.npy')\n",
    "train_targets_pl = pd.read_csv('../input/best-lb/submission.csv')\n",
    "train_features_pl = pd.read_csv('../input/test-public-moa/test_features.csv')\n",
    "\n",
    "ss = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:45:43.566288Z",
     "iopub.status.busy": "2020-11-24T18:45:43.564316Z",
     "iopub.status.idle": "2020-11-24T18:45:43.567483Z",
     "shell.execute_reply": "2020-11-24T18:45:43.568077Z"
    },
    "papermill": {
     "duration": 0.046441,
     "end_time": "2020-11-24T18:45:43.568226",
     "exception": false,
     "start_time": "2020-11-24T18:45:43.521785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:45:44.034375Z",
     "iopub.status.busy": "2020-11-24T18:45:44.033281Z",
     "iopub.status.idle": "2020-11-24T18:45:44.036916Z",
     "shell.execute_reply": "2020-11-24T18:45:44.036335Z"
    },
    "papermill": {
     "duration": 0.44648,
     "end_time": "2020-11-24T18:45:44.037053",
     "exception": false,
     "start_time": "2020-11-24T18:45:43.590573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nfolds = 7\n",
    "nstarts = 3\n",
    "nepochs = 50\n",
    "fold_seed = 42\n",
    "batch_size = 128\n",
    "val_batch_size = batch_size * 4\n",
    "ntargets = 206\n",
    "# targets = [col for col in train_targets.columns]\n",
    "val_criterion = nn.BCEWithLogitsLoss()\n",
    "trn_criterion = SmoothBCEwLogits(smoothing=0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "genes_comp = 80\n",
    "cells_comp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:45:44.092328Z",
     "iopub.status.busy": "2020-11-24T18:45:44.090870Z",
     "iopub.status.idle": "2020-11-24T18:45:44.201454Z",
     "shell.execute_reply": "2020-11-24T18:45:44.200859Z"
    },
    "papermill": {
     "duration": 0.142116,
     "end_time": "2020-11-24T18:45:44.201580",
     "exception": false,
     "start_time": "2020-11-24T18:45:44.059464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "train = preprocess(train_features)\n",
    "test = preprocess(test_features)\n",
    "train_pl = preprocess(train_features_pl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:45:44.257823Z",
     "iopub.status.busy": "2020-11-24T18:45:44.256737Z",
     "iopub.status.idle": "2020-11-24T18:46:25.582987Z",
     "shell.execute_reply": "2020-11-24T18:46:25.582209Z"
    },
    "papermill": {
     "duration": 41.359185,
     "end_time": "2020-11-24T18:46:25.583126",
     "exception": false,
     "start_time": "2020-11-24T18:45:44.223941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantile(tr, te, feats):\n",
    "    data_all = pd.concat([tr, te], ignore_index = True)\n",
    "    scaler = GaussRankScaler()\n",
    "    data_all[feats] = scaler.fit_transform(data_all[feats])\n",
    "    \n",
    "    tr = data_all[:len(tr)]\n",
    "    te = data_all[len(tr):]\n",
    "    \n",
    "    return tr, te\n",
    "\n",
    "_, train_pl = quantile(train, train_pl, GENES)\n",
    "_, train_pl = quantile(_, train_pl, CELLS)\n",
    "train, test = quantile(train, test, GENES)\n",
    "train, test = quantile(train, test, CELLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:25.645063Z",
     "iopub.status.busy": "2020-11-24T18:46:25.643452Z",
     "iopub.status.idle": "2020-11-24T18:46:30.991153Z",
     "shell.execute_reply": "2020-11-24T18:46:30.989473Z"
    },
    "papermill": {
     "duration": 5.385231,
     "end_time": "2020-11-24T18:46:30.991359",
     "exception": false,
     "start_time": "2020-11-24T18:46:25.606128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca(tr, te, feats, n_components, group):\n",
    "    data_all = pd.concat([tr, te])\n",
    "    pca_transformer = PCA(n_components=n_components, random_state=42)\n",
    "    data_pca = pca_transformer.fit_transform(data_all[feats])\n",
    "    \n",
    "    if group == 'genes':\n",
    "        cols = [f'pca_G-{i}' for i in range(n_components)]\n",
    "    elif group == 'cells':\n",
    "        cols = [f'pca_C-{i}' for i in range(n_components)]\n",
    "    \n",
    "    data_all = pd.concat([data_all, pd.DataFrame(data_pca, columns=cols)], axis=1)\n",
    "    \n",
    "    tr = data_all[:len(tr)]\n",
    "    te = data_all[len(tr):]\n",
    "    \n",
    "    return tr, te\n",
    "\n",
    "_, train_pl = pca(train, train_pl, GENES, genes_comp, 'genes')\n",
    "_, train_pl = pca(_, train_pl, CELLS, cells_comp, 'cells')\n",
    "train, test = pca(train, test, GENES, genes_comp, 'genes')\n",
    "train, test = pca(train, test, CELLS, cells_comp, 'cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:31.109645Z",
     "iopub.status.busy": "2020-11-24T18:46:31.108460Z",
     "iopub.status.idle": "2020-11-24T18:46:31.202241Z",
     "shell.execute_reply": "2020-11-24T18:46:31.203466Z"
    },
    "papermill": {
     "duration": 0.172613,
     "end_time": "2020-11-24T18:46:31.203711",
     "exception": false,
     "start_time": "2020-11-24T18:46:31.031098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = train_targets.columns[1:]\n",
    "train_targets = train_targets.merge(drug_ids, on='sig_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:31.360576Z",
     "iopub.status.busy": "2020-11-24T18:46:31.350142Z",
     "iopub.status.idle": "2020-11-24T18:46:31.385011Z",
     "shell.execute_reply": "2020-11-24T18:46:31.386472Z"
    },
    "papermill": {
     "duration": 0.136205,
     "end_time": "2020-11-24T18:46:31.386696",
     "exception": false,
     "start_time": "2020-11-24T18:46:31.250491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pl = train_pl.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:31.556436Z",
     "iopub.status.busy": "2020-11-24T18:46:31.555387Z",
     "iopub.status.idle": "2020-11-24T18:46:32.186207Z",
     "shell.execute_reply": "2020-11-24T18:46:32.187029Z"
    },
    "papermill": {
     "duration": 0.731263,
     "end_time": "2020-11-24T18:46:32.187260",
     "exception": false,
     "start_time": "2020-11-24T18:46:31.455997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True)\n",
    "train_targets_pl = train_targets_pl.loc[train_pl['cp_type']==0].reset_index(drop=True)\n",
    "train = train.loc[train['cp_type']==0].reset_index(drop=True)\n",
    "train_pl = train_pl.loc[train_pl['cp_type']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.267645Z",
     "iopub.status.busy": "2020-11-24T18:46:32.266645Z",
     "iopub.status.idle": "2020-11-24T18:46:32.288641Z",
     "shell.execute_reply": "2020-11-24T18:46:32.289871Z"
    },
    "papermill": {
     "duration": 0.06639,
     "end_time": "2020-11-24T18:46:32.290145",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.223755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.372331Z",
     "iopub.status.busy": "2020-11-24T18:46:32.369258Z",
     "iopub.status.idle": "2020-11-24T18:46:32.397713Z",
     "shell.execute_reply": "2020-11-24T18:46:32.399020Z"
    },
    "papermill": {
     "duration": 0.073617,
     "end_time": "2020-11-24T18:46:32.399203",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.325586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       129\n",
       "2         3\n",
       "3         2\n",
       "4         3\n",
       "5        66\n",
       "6      2774\n",
       "7       196\n",
       "8         4\n",
       "11        4\n",
       "12       64\n",
       "13       25\n",
       "14        6\n",
       "18        3\n",
       "19        1\n",
       "178       1\n",
       "186       1\n",
       "194       1\n",
       "196       1\n",
       "202       1\n",
       "203       1\n",
       "246       1\n",
       "718       1\n",
       "Name: drug_id, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets['fold'] = folds\n",
    "train_targets.drug_id.value_counts().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.490799Z",
     "iopub.status.busy": "2020-11-24T18:46:32.483602Z",
     "iopub.status.idle": "2020-11-24T18:46:32.492023Z",
     "shell.execute_reply": "2020-11-24T18:46:32.492973Z"
    },
    "papermill": {
     "duration": 0.055763,
     "end_time": "2020-11-24T18:46:32.493191",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.437428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.563335Z",
     "iopub.status.busy": "2020-11-24T18:46:32.562267Z",
     "iopub.status.idle": "2020-11-24T18:46:32.581479Z",
     "shell.execute_reply": "2020-11-24T18:46:32.580894Z"
    },
    "papermill": {
     "duration": 0.048215,
     "end_time": "2020-11-24T18:46:32.581601",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.533386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoaModel(nn.Module):\n",
    "    def __init__(self, num_columns):\n",
    "        super(MoaModel, self).__init__()\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(2048)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1048))\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(1048)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(1048, 1048))\n",
    "        \n",
    "        self.batch_norm4 = nn.BatchNorm1d(1048)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "        self.dense4 = nn.utils.weight_norm(nn.Linear(1048, 206))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.dense3(x))\n",
    "        \n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.dense4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.664778Z",
     "iopub.status.busy": "2020-11-24T18:46:32.638516Z",
     "iopub.status.idle": "2020-11-24T18:46:32.708480Z",
     "shell.execute_reply": "2020-11-24T18:46:32.709104Z"
    },
    "papermill": {
     "duration": 0.102002,
     "end_time": "2020-11-24T18:46:32.709272",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.607270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "top_feats = [  1,   2,   3,   4,   5,   6,   7,   9,  11,  14,  15,  16,  17,\n",
    "        18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
    "        32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,\n",
    "        47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,\n",
    "        61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
    "        74,  75,  76,  78,  79,  80,  81,  82,  83,  84,  86,  87,  88,\n",
    "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
    "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
    "       115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
    "       129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143,\n",
    "       144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
    "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
    "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
    "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n",
    "       198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212,\n",
    "       213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226,\n",
    "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
    "       240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
    "       254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
    "       267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
    "       281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294,\n",
    "       295, 296, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
    "       310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
    "       324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
    "       337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
    "       350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
    "       363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376, 377,\n",
    "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391,\n",
    "       392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
    "       405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 416, 417, 418,\n",
    "       419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
    "       432, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446,\n",
    "       447, 448, 449, 450, 453, 454, 456, 457, 458, 459, 460, 461, 462,\n",
    "       463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
    "       476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
    "       490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505,\n",
    "       506, 507, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521,\n",
    "       522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 534, 535, 536,\n",
    "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551,\n",
    "       552, 554, 557, 559, 560, 561, 562, 565, 566, 567, 568, 569, 570,\n",
    "       571, 572, 573, 574, 575, 577, 578, 580, 581, 582, 583, 584, 585,\n",
    "       586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 599,\n",
    "       600, 601, 602, 606, 607, 608, 609, 611, 612, 613, 615, 616, 617,\n",
    "       618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
    "       631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 644,\n",
    "       645, 646, 647, 648, 649, 650, 651, 652, 654, 655, 656, 658, 659,\n",
    "       660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,\n",
    "       673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
    "       686, 687, 688, 689, 691, 692, 693, 694, 695, 696, 697, 699, 700,\n",
    "       701, 702, 704, 705, 707, 708, 709, 710, 711, 713, 714, 716, 717,\n",
    "       718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n",
    "       733, 734, 735, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747,\n",
    "       748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 760, 761,\n",
    "       762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774,\n",
    "       775, 776, 777, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788,\n",
    "       789, 790, 792, 793, 794, 795, 796, 797, 798, 800, 801, 802, 803,\n",
    "       804, 805, 806, 808, 809, 811, 813, 814, 815, 816, 817, 818, 819,\n",
    "       821, 822, 823, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835,\n",
    "       837, 838, 839, 840, 841, 842, 845, 846, 847, 848, 850, 851, 852,\n",
    "       854, 855, 856, 858, 859, 860, 861, 862, 864, 866, 867, 868, 869,\n",
    "       870, 871, 872, 873, 874]\n",
    "print(len(top_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.767494Z",
     "iopub.status.busy": "2020-11-24T18:46:32.766766Z",
     "iopub.status.idle": "2020-11-24T18:46:32.771981Z",
     "shell.execute_reply": "2020-11-24T18:46:32.771331Z"
    },
    "papermill": {
     "duration": 0.036928,
     "end_time": "2020-11-24T18:46:32.772153",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.735225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add pca feature indices to feature indices\n",
    "pca_feats = [i for i in range(875, 875+genes_comp+cells_comp)]\n",
    "top_feats.extend(pca_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.837714Z",
     "iopub.status.busy": "2020-11-24T18:46:32.835517Z",
     "iopub.status.idle": "2020-11-24T18:46:32.838590Z",
     "shell.execute_reply": "2020-11-24T18:46:32.839171Z"
    },
    "papermill": {
     "duration": 0.041175,
     "end_time": "2020-11-24T18:46:32.839314",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.798139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset class\n",
    "class MoaDataset(Dataset):\n",
    "    def __init__(self, df, targets, feats_idx, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.feats = feats_idx\n",
    "        self.data = df[:, feats_idx]\n",
    "        if mode=='train':\n",
    "            self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(self.targets[idx])\n",
    "        elif self.mode == 'test':\n",
    "            return torch.FloatTensor(self.data[idx]), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.900110Z",
     "iopub.status.busy": "2020-11-24T18:46:32.898543Z",
     "iopub.status.idle": "2020-11-24T18:46:32.900933Z",
     "shell.execute_reply": "2020-11-24T18:46:32.901479Z"
    },
    "papermill": {
     "duration": 0.035592,
     "end_time": "2020-11-24T18:46:32.901621",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.866029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = train_targets.fold.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:32.962902Z",
     "iopub.status.busy": "2020-11-24T18:46:32.961340Z",
     "iopub.status.idle": "2020-11-24T18:46:33.085055Z",
     "shell.execute_reply": "2020-11-24T18:46:33.084385Z"
    },
    "papermill": {
     "duration": 0.156712,
     "end_time": "2020-11-24T18:46:33.085187",
     "exception": false,
     "start_time": "2020-11-24T18:46:32.928475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.values\n",
    "train_pl = train_pl.values\n",
    "test = test.values\n",
    "train_targets = train_targets[targets].values\n",
    "train_targets_pl = train_targets_pl[targets].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-11-24T18:46:33.167463Z",
     "iopub.status.busy": "2020-11-24T18:46:33.166575Z",
     "iopub.status.idle": "2020-11-24T19:26:45.857592Z",
     "shell.execute_reply": "2020-11-24T19:26:45.858283Z"
    },
    "papermill": {
     "duration": 2412.746477,
     "end_time": "2020-11-24T19:26:45.858459",
     "exception": false,
     "start_time": "2020-11-24T18:46:33.111982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seed 0\n",
      "Train fold 1\n",
      "Epoch 1/50   -   loss: 0.26647   -   val_loss: 0.04046\n",
      "Epoch 2/50   -   loss: 0.03313   -   val_loss: 0.02485\n",
      "Epoch 3/50   -   loss: 0.02520   -   val_loss: 0.02036\n",
      "Epoch 4/50   -   loss: 0.02302   -   val_loss: 0.01900\n",
      "Epoch 5/50   -   loss: 0.02192   -   val_loss: 0.01832\n",
      "Epoch 6/50   -   loss: 0.02144   -   val_loss: 0.01797\n",
      "Epoch 7/50   -   loss: 0.02120   -   val_loss: 0.01776\n",
      "Epoch 8/50   -   loss: 0.02086   -   val_loss: 0.01752\n",
      "Epoch 9/50   -   loss: 0.02127   -   val_loss: 0.01892\n",
      "Epoch 10/50   -   loss: 0.02189   -   val_loss: 0.01730\n",
      "Epoch 11/50   -   loss: 0.02088   -   val_loss: 0.01722\n",
      "Epoch 12/50   -   loss: 0.02054   -   val_loss: 0.01723\n",
      "Epoch 13/50   -   loss: 0.02033   -   val_loss: 0.01723\n",
      "Epoch 14/50   -   loss: 0.02028   -   val_loss: 0.01718\n",
      "Epoch 15/50   -   loss: 0.02021   -   val_loss: 0.01731\n",
      "Epoch 16/50   -   loss: 0.02020   -   val_loss: 0.01723\n",
      "Epoch 17/50   -   loss: 0.02017   -   val_loss: 0.01722\n",
      "Epoch 18/50   -   loss: 0.02012   -   val_loss: 0.01725\n",
      "Epoch 19/50   -   loss: 0.02006   -   val_loss: 0.01724\n",
      "Epoch 20/50   -   loss: 0.02000   -   val_loss: 0.01719\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 21/50   -   loss: 0.01957   -   val_loss: 0.01689\n",
      "Epoch 22/50   -   loss: 0.01927   -   val_loss: 0.01689\n",
      "Epoch 23/50   -   loss: 0.01911   -   val_loss: 0.01686\n",
      "Epoch 24/50   -   loss: 0.01902   -   val_loss: 0.01680\n",
      "Epoch 25/50   -   loss: 0.01890   -   val_loss: 0.01682\n",
      "Epoch 26/50   -   loss: 0.01882   -   val_loss: 0.01685\n",
      "Epoch 27/50   -   loss: 0.01869   -   val_loss: 0.01687\n",
      "Epoch 28/50   -   loss: 0.01856   -   val_loss: 0.01684\n",
      "Epoch 29/50   -   loss: 0.01847   -   val_loss: 0.01688\n",
      "Epoch 30/50   -   loss: 0.01836   -   val_loss: 0.01687\n",
      "Epoch 31/50   -   loss: 0.01822   -   val_loss: 0.01683\n",
      "Epoch 32/50   -   loss: 0.01816   -   val_loss: 0.01687\n",
      "Epoch 33/50   -   loss: 0.01805   -   val_loss: 0.01689\n",
      "Epoch 34/50   -   loss: 0.01792   -   val_loss: 0.01695\n",
      "Epoch 35/50   -   loss: 0.01785   -   val_loss: 0.01691\n",
      "Epoch 36/50   -   loss: 0.01770   -   val_loss: 0.01701\n",
      "Epoch 37/50   -   loss: 0.01755   -   val_loss: 0.01695\n",
      "Epoch 38/50   -   loss: 0.01747   -   val_loss: 0.01695\n",
      "Epoch 39/50   -   loss: 0.01734   -   val_loss: 0.01701\n",
      "Epoch 40/50   -   loss: 0.01723   -   val_loss: 0.01705\n",
      "Epoch 41/50   -   loss: 0.01716   -   val_loss: 0.01701\n",
      "Epoch 42/50   -   loss: 0.01704   -   val_loss: 0.01703\n",
      "Epoch 43/50   -   loss: 0.01691   -   val_loss: 0.01699\n",
      "Epoch 44/50   -   loss: 0.01683   -   val_loss: 0.01708\n",
      "Epoch 45/50   -   loss: 0.01672   -   val_loss: 0.01715\n",
      "Epoch 46/50   -   loss: 0.01661   -   val_loss: 0.01704\n",
      "Epoch 47/50   -   loss: 0.01657   -   val_loss: 0.01713\n",
      "Epoch 48/50   -   loss: 0.01640   -   val_loss: 0.01707\n",
      "Epoch 49/50   -   loss: 0.01638   -   val_loss: 0.01714\n",
      "Epoch 50/50   -   loss: 0.01629   -   val_loss: 0.01708\n",
      "Train fold 2\n",
      "Epoch 1/50   -   loss: 0.26879   -   val_loss: 0.04082\n",
      "Epoch 2/50   -   loss: 0.03360   -   val_loss: 0.02416\n",
      "Epoch 3/50   -   loss: 0.02558   -   val_loss: 0.02013\n",
      "Epoch 4/50   -   loss: 0.02334   -   val_loss: 0.01884\n",
      "Epoch 5/50   -   loss: 0.02232   -   val_loss: 0.01791\n",
      "Epoch 6/50   -   loss: 0.02150   -   val_loss: 0.01753\n",
      "Epoch 7/50   -   loss: 0.02117   -   val_loss: 0.01751\n",
      "Epoch 8/50   -   loss: 0.02117   -   val_loss: 0.01863\n",
      "Epoch 9/50   -   loss: 0.02140   -   val_loss: 0.01727\n",
      "Epoch 10/50   -   loss: 0.02079   -   val_loss: 0.01704\n",
      "Epoch 11/50   -   loss: 0.02060   -   val_loss: 0.01704\n",
      "Epoch 12/50   -   loss: 0.02039   -   val_loss: 0.01696\n",
      "Epoch 13/50   -   loss: 0.02043   -   val_loss: 0.01700\n",
      "Epoch 14/50   -   loss: 0.02028   -   val_loss: 0.01702\n",
      "Epoch 15/50   -   loss: 0.02019   -   val_loss: 0.01705\n",
      "Epoch 16/50   -   loss: 0.02017   -   val_loss: 0.01705\n",
      "Epoch 17/50   -   loss: 0.02016   -   val_loss: 0.01719\n",
      "Epoch 18/50   -   loss: 0.02016   -   val_loss: 0.01692\n",
      "Epoch 19/50   -   loss: 0.02012   -   val_loss: 0.01696\n",
      "Epoch 20/50   -   loss: 0.02007   -   val_loss: 0.01693\n",
      "Epoch 21/50   -   loss: 0.02011   -   val_loss: 0.01690\n",
      "Epoch 22/50   -   loss: 0.02001   -   val_loss: 0.01693\n",
      "Epoch 23/50   -   loss: 0.01994   -   val_loss: 0.01688\n",
      "Epoch 24/50   -   loss: 0.01995   -   val_loss: 0.01680\n",
      "Epoch 25/50   -   loss: 0.01993   -   val_loss: 0.01695\n",
      "Epoch 26/50   -   loss: 0.01993   -   val_loss: 0.01699\n",
      "Epoch 27/50   -   loss: 0.01992   -   val_loss: 0.01683\n",
      "Epoch 28/50   -   loss: 0.01996   -   val_loss: 0.01686\n",
      "Epoch 29/50   -   loss: 0.01991   -   val_loss: 0.01684\n",
      "Epoch 30/50   -   loss: 0.01990   -   val_loss: 0.01693\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 31/50   -   loss: 0.01940   -   val_loss: 0.01674\n",
      "Epoch 32/50   -   loss: 0.01916   -   val_loss: 0.01670\n",
      "Epoch 33/50   -   loss: 0.01899   -   val_loss: 0.01673\n",
      "Epoch 34/50   -   loss: 0.01886   -   val_loss: 0.01670\n",
      "Epoch 35/50   -   loss: 0.01877   -   val_loss: 0.01671\n",
      "Epoch 36/50   -   loss: 0.01863   -   val_loss: 0.01670\n",
      "Epoch 37/50   -   loss: 0.01860   -   val_loss: 0.01668\n",
      "Epoch 38/50   -   loss: 0.01851   -   val_loss: 0.01673\n",
      "Epoch 39/50   -   loss: 0.01837   -   val_loss: 0.01670\n",
      "Epoch 40/50   -   loss: 0.01829   -   val_loss: 0.01675\n",
      "Epoch 41/50   -   loss: 0.01823   -   val_loss: 0.01673\n",
      "Epoch 42/50   -   loss: 0.01809   -   val_loss: 0.01676\n",
      "Epoch 43/50   -   loss: 0.01804   -   val_loss: 0.01679\n",
      "Epoch 44/50   -   loss: 0.01795   -   val_loss: 0.01680\n",
      "Epoch 45/50   -   loss: 0.01788   -   val_loss: 0.01679\n",
      "Epoch 46/50   -   loss: 0.01773   -   val_loss: 0.01681\n",
      "Epoch 47/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 48/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 49/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 3\n",
      "Epoch 1/50   -   loss: 0.26713   -   val_loss: 0.04086\n",
      "Epoch 2/50   -   loss: 0.03331   -   val_loss: 0.02437\n",
      "Epoch 3/50   -   loss: 0.02535   -   val_loss: 0.02074\n",
      "Epoch 4/50   -   loss: 0.02320   -   val_loss: 0.01933\n",
      "Epoch 5/50   -   loss: 0.02214   -   val_loss: 0.01867\n",
      "Epoch 6/50   -   loss: 0.02143   -   val_loss: 0.01800\n",
      "Epoch 7/50   -   loss: 0.02104   -   val_loss: 0.01788\n",
      "Epoch 8/50   -   loss: 0.02074   -   val_loss: 0.01809\n",
      "Epoch 9/50   -   loss: 0.02073   -   val_loss: 0.01799\n",
      "Epoch 10/50   -   loss: 0.02055   -   val_loss: 0.01769\n",
      "Epoch 11/50   -   loss: 0.02032   -   val_loss: 0.01737\n",
      "Epoch 12/50   -   loss: 0.02014   -   val_loss: 0.01761\n",
      "Epoch 13/50   -   loss: 0.02014   -   val_loss: 0.01737\n",
      "Epoch 14/50   -   loss: 0.02014   -   val_loss: 0.01752\n",
      "Epoch 15/50   -   loss: 0.02004   -   val_loss: 0.01734\n",
      "Epoch 16/50   -   loss: 0.01997   -   val_loss: 0.01743\n",
      "Epoch 17/50   -   loss: 0.01998   -   val_loss: 0.01745\n",
      "Epoch 18/50   -   loss: 0.02018   -   val_loss: 0.01752\n",
      "Epoch 19/50   -   loss: 0.01995   -   val_loss: 0.01745\n",
      "Epoch 20/50   -   loss: 0.01988   -   val_loss: 0.01742\n",
      "Epoch 21/50   -   loss: 0.01990   -   val_loss: 0.01758\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 22/50   -   loss: 0.01940   -   val_loss: 0.01721\n",
      "Epoch 23/50   -   loss: 0.01909   -   val_loss: 0.01720\n",
      "Epoch 24/50   -   loss: 0.01894   -   val_loss: 0.01716\n",
      "Epoch 25/50   -   loss: 0.01884   -   val_loss: 0.01719\n",
      "Epoch 26/50   -   loss: 0.01873   -   val_loss: 0.01716\n",
      "Epoch 27/50   -   loss: 0.01862   -   val_loss: 0.01714\n",
      "Epoch 28/50   -   loss: 0.01853   -   val_loss: 0.01718\n",
      "Epoch 29/50   -   loss: 0.01841   -   val_loss: 0.01716\n",
      "Epoch 30/50   -   loss: 0.01832   -   val_loss: 0.01719\n",
      "Epoch 31/50   -   loss: 0.01822   -   val_loss: 0.01719\n",
      "Epoch 32/50   -   loss: 0.01816   -   val_loss: 0.01715\n",
      "Epoch 33/50   -   loss: 0.01805   -   val_loss: 0.01722\n",
      "Epoch 34/50   -   loss: 0.01792   -   val_loss: 0.01723\n",
      "Epoch 35/50   -   loss: 0.01782   -   val_loss: 0.01719\n",
      "Epoch 36/50   -   loss: 0.01774   -   val_loss: 0.01724\n",
      "Epoch 37/50   -   loss: 0.01764   -   val_loss: 0.01729\n",
      "Epoch 38/50   -   loss: 0.01754   -   val_loss: 0.01736\n",
      "Epoch 39/50   -   loss: 0.01742   -   val_loss: 0.01730\n",
      "Epoch 40/50   -   loss: 0.01728   -   val_loss: 0.01724\n",
      "Epoch 41/50   -   loss: 0.01723   -   val_loss: 0.01733\n",
      "Epoch 42/50   -   loss: 0.01712   -   val_loss: 0.01737\n",
      "Epoch 43/50   -   loss: 0.01700   -   val_loss: 0.01732\n",
      "Epoch 44/50   -   loss: 0.01690   -   val_loss: 0.01740\n",
      "Epoch 45/50   -   loss: 0.01683   -   val_loss: 0.01736\n",
      "Epoch 46/50   -   loss: 0.01670   -   val_loss: 0.01746\n",
      "Epoch 47/50   -   loss: 0.01658   -   val_loss: 0.01742\n",
      "Epoch 48/50   -   loss: 0.01655   -   val_loss: 0.01746\n",
      "Epoch 49/50   -   loss: 0.01644   -   val_loss: 0.01752\n",
      "Epoch 50/50   -   loss: 0.01638   -   val_loss: 0.01753\n",
      "Train fold 4\n",
      "Epoch 1/50   -   loss: 0.26540   -   val_loss: 0.04223\n",
      "Epoch 2/50   -   loss: 0.03345   -   val_loss: 0.02418\n",
      "Epoch 3/50   -   loss: 0.02542   -   val_loss: 0.02024\n",
      "Epoch 4/50   -   loss: 0.02315   -   val_loss: 0.01877\n",
      "Epoch 5/50   -   loss: 0.02212   -   val_loss: 0.01801\n",
      "Epoch 6/50   -   loss: 0.02149   -   val_loss: 0.01735\n",
      "Epoch 7/50   -   loss: 0.02114   -   val_loss: 0.01711\n",
      "Epoch 8/50   -   loss: 0.02086   -   val_loss: 0.01705\n",
      "Epoch 9/50   -   loss: 0.02067   -   val_loss: 0.01703\n",
      "Epoch 10/50   -   loss: 0.02050   -   val_loss: 0.01704\n",
      "Epoch 11/50   -   loss: 0.02051   -   val_loss: 0.01707\n",
      "Epoch 12/50   -   loss: 0.02193   -   val_loss: 0.01687\n",
      "Epoch 13/50   -   loss: 0.02073   -   val_loss: 0.01693\n",
      "Epoch 14/50   -   loss: 0.02047   -   val_loss: 0.01681\n",
      "Epoch 15/50   -   loss: 0.02039   -   val_loss: 0.01672\n",
      "Epoch 16/50   -   loss: 0.02020   -   val_loss: 0.01666\n",
      "Epoch 17/50   -   loss: 0.02009   -   val_loss: 0.01672\n",
      "Epoch 18/50   -   loss: 0.02010   -   val_loss: 0.01666\n",
      "Epoch 19/50   -   loss: 0.02005   -   val_loss: 0.01660\n",
      "Epoch 20/50   -   loss: 0.02004   -   val_loss: 0.01671\n",
      "Epoch 21/50   -   loss: 0.02007   -   val_loss: 0.01670\n",
      "Epoch 22/50   -   loss: 0.02000   -   val_loss: 0.01658\n",
      "Epoch 23/50   -   loss: 0.01999   -   val_loss: 0.01664\n",
      "Epoch 24/50   -   loss: 0.02000   -   val_loss: 0.01667\n",
      "Epoch 25/50   -   loss: 0.01993   -   val_loss: 0.01657\n",
      "Epoch 26/50   -   loss: 0.01999   -   val_loss: 0.01663\n",
      "Epoch 27/50   -   loss: 0.01991   -   val_loss: 0.01654\n",
      "Epoch 28/50   -   loss: 0.01992   -   val_loss: 0.01662\n",
      "Epoch 29/50   -   loss: 0.02000   -   val_loss: 0.01663\n",
      "Epoch 30/50   -   loss: 0.01997   -   val_loss: 0.01665\n",
      "Epoch 31/50   -   loss: 0.01993   -   val_loss: 0.01657\n",
      "Epoch 32/50   -   loss: 0.01991   -   val_loss: 0.01653\n",
      "Epoch 33/50   -   loss: 0.01996   -   val_loss: 0.01658\n",
      "Epoch 34/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 35/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 36/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 37/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 38/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 39/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 40/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 41/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 42/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 43/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 44/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 45/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 46/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 47/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 48/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 49/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 5\n",
      "Epoch 1/50   -   loss: 0.26717   -   val_loss: 0.04361\n",
      "Epoch 2/50   -   loss: 0.03324   -   val_loss: 0.02385\n",
      "Epoch 3/50   -   loss: 0.02532   -   val_loss: 0.02041\n",
      "Epoch 4/50   -   loss: 0.02314   -   val_loss: 0.01900\n",
      "Epoch 5/50   -   loss: 0.02195   -   val_loss: 0.01816\n",
      "Epoch 6/50   -   loss: 0.02134   -   val_loss: 0.01794\n",
      "Epoch 7/50   -   loss: 0.02104   -   val_loss: 0.01775\n",
      "Epoch 8/50   -   loss: 0.02096   -   val_loss: 0.01753\n",
      "Epoch 9/50   -   loss: 0.02059   -   val_loss: 0.01773\n",
      "Epoch 10/50   -   loss: 0.02043   -   val_loss: 0.01741\n",
      "Epoch 11/50   -   loss: 0.02034   -   val_loss: 0.01729\n",
      "Epoch 12/50   -   loss: 0.02026   -   val_loss: 0.01732\n",
      "Epoch 13/50   -   loss: 0.02008   -   val_loss: 0.01733\n",
      "Epoch 14/50   -   loss: 0.02014   -   val_loss: 0.01730\n",
      "Epoch 15/50   -   loss: 0.02014   -   val_loss: 0.01729\n",
      "Epoch 16/50   -   loss: 0.01997   -   val_loss: 0.01752\n",
      "Epoch 17/50   -   loss: 0.02001   -   val_loss: 0.01709\n",
      "Epoch 18/50   -   loss: 0.01989   -   val_loss: 0.01723\n",
      "Epoch 19/50   -   loss: 0.02000   -   val_loss: 0.01732\n",
      "Epoch 20/50   -   loss: 0.01990   -   val_loss: 0.01717\n",
      "Epoch 21/50   -   loss: 0.01989   -   val_loss: 0.01709\n",
      "Epoch 22/50   -   loss: 0.01984   -   val_loss: 0.01729\n",
      "Epoch 23/50   -   loss: 0.01983   -   val_loss: 0.01741\n",
      "Epoch 24/50   -   loss: 0.01985   -   val_loss: 0.01748\n",
      "Epoch 25/50   -   loss: 0.01989   -   val_loss: 0.01723\n",
      "Epoch 26/50   -   loss: 0.01986   -   val_loss: 0.01745\n",
      "Epoch 27/50   -   loss: 0.01986   -   val_loss: 0.01724\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 28/50   -   loss: 0.01934   -   val_loss: 0.01700\n",
      "Epoch 29/50   -   loss: 0.01904   -   val_loss: 0.01698\n",
      "Epoch 30/50   -   loss: 0.01893   -   val_loss: 0.01701\n",
      "Epoch 31/50   -   loss: 0.01875   -   val_loss: 0.01704\n",
      "Epoch 32/50   -   loss: 0.01867   -   val_loss: 0.01702\n",
      "Epoch 33/50   -   loss: 0.01857   -   val_loss: 0.01707\n",
      "Epoch 34/50   -   loss: 0.01847   -   val_loss: 0.01709\n",
      "Epoch 35/50   -   loss: 0.01841   -   val_loss: 0.01708\n",
      "Epoch 36/50   -   loss: 0.01825   -   val_loss: 0.01713\n",
      "Epoch 37/50   -   loss: 0.01819   -   val_loss: 0.01712\n",
      "Epoch 38/50   -   loss: 0.01815   -   val_loss: 0.01707\n",
      "Epoch 39/50   -   loss: 0.01802   -   val_loss: 0.01715\n",
      "Epoch 40/50   -   loss: 0.01793   -   val_loss: 0.01715\n",
      "Epoch 41/50   -   loss: 0.01785   -   val_loss: 0.01717\n",
      "Epoch 42/50   -   loss: 0.01775   -   val_loss: 0.01716\n",
      "Epoch 43/50   -   loss: 0.01768   -   val_loss: 0.01727\n",
      "Epoch 44/50   -   loss: 0.01761   -   val_loss: 0.01724\n",
      "Epoch 45/50   -   loss: 0.01751   -   val_loss: 0.01735\n",
      "Epoch 46/50   -   loss: 0.01744   -   val_loss: 0.01727\n",
      "Epoch 47/50   -   loss: 0.01736   -   val_loss: 0.01737\n",
      "Epoch 48/50   -   loss: 0.01723   -   val_loss: 0.01734\n",
      "Epoch 49/50   -   loss: 0.01717   -   val_loss: 0.01739\n",
      "Epoch 50/50   -   loss: 0.01710   -   val_loss: 0.01730\n",
      "Train fold 6\n",
      "Epoch 1/50   -   loss: 0.26779   -   val_loss: 0.04341\n",
      "Epoch 2/50   -   loss: 0.03314   -   val_loss: 0.02413\n",
      "Epoch 3/50   -   loss: 0.02548   -   val_loss: 0.02050\n",
      "Epoch 4/50   -   loss: 0.02327   -   val_loss: 0.01894\n",
      "Epoch 5/50   -   loss: 0.02208   -   val_loss: 0.01927\n",
      "Epoch 6/50   -   loss: 0.02157   -   val_loss: 0.01788\n",
      "Epoch 7/50   -   loss: 0.02146   -   val_loss: 0.01778\n",
      "Epoch 8/50   -   loss: 0.02109   -   val_loss: 0.01771\n",
      "Epoch 9/50   -   loss: 0.02074   -   val_loss: 0.01742\n",
      "Epoch 10/50   -   loss: 0.02052   -   val_loss: 0.01727\n",
      "Epoch 11/50   -   loss: 0.02047   -   val_loss: 0.01732\n",
      "Epoch 12/50   -   loss: 0.02024   -   val_loss: 0.01718\n",
      "Epoch 13/50   -   loss: 0.02027   -   val_loss: 0.01725\n",
      "Epoch 14/50   -   loss: 0.02016   -   val_loss: 0.01717\n",
      "Epoch 15/50   -   loss: 0.02005   -   val_loss: 0.01742\n",
      "Epoch 16/50   -   loss: 0.02005   -   val_loss: 0.01727\n",
      "Epoch 17/50   -   loss: 0.02010   -   val_loss: 0.01720\n",
      "Epoch 18/50   -   loss: 0.01998   -   val_loss: 0.01715\n",
      "Epoch 19/50   -   loss: 0.01995   -   val_loss: 0.01729\n",
      "Epoch 20/50   -   loss: 0.01990   -   val_loss: 0.01716\n",
      "Epoch 21/50   -   loss: 0.01991   -   val_loss: 0.01732\n",
      "Epoch 22/50   -   loss: 0.01985   -   val_loss: 0.01740\n",
      "Epoch 23/50   -   loss: 0.01985   -   val_loss: 0.01714\n",
      "Epoch 24/50   -   loss: 0.01983   -   val_loss: 0.01716\n",
      "Epoch 25/50   -   loss: 0.01988   -   val_loss: 0.01715\n",
      "Epoch 26/50   -   loss: 0.01986   -   val_loss: 0.01749\n",
      "Epoch 27/50   -   loss: 0.01982   -   val_loss: 0.01720\n",
      "Epoch 28/50   -   loss: 0.01979   -   val_loss: 0.01736\n",
      "Epoch 29/50   -   loss: 0.01984   -   val_loss: 0.01727\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 30/50   -   loss: 0.01924   -   val_loss: 0.01701\n",
      "Epoch 31/50   -   loss: 0.01902   -   val_loss: 0.01701\n",
      "Epoch 32/50   -   loss: 0.01889   -   val_loss: 0.01702\n",
      "Epoch 33/50   -   loss: 0.01878   -   val_loss: 0.01704\n",
      "Epoch 34/50   -   loss: 0.01865   -   val_loss: 0.01706\n",
      "Epoch 35/50   -   loss: 0.01854   -   val_loss: 0.01701\n",
      "Epoch 36/50   -   loss: 0.01849   -   val_loss: 0.01708\n",
      "Epoch 37/50   -   loss: 0.01839   -   val_loss: 0.01705\n",
      "Epoch 38/50   -   loss: 0.01831   -   val_loss: 0.01707\n",
      "Epoch 39/50   -   loss: 0.01818   -   val_loss: 0.01710\n",
      "Epoch 40/50   -   loss: 0.01814   -   val_loss: 0.01716\n",
      "Epoch 41/50   -   loss: 0.01803   -   val_loss: 0.01716\n",
      "Epoch 42/50   -   loss: 0.01797   -   val_loss: 0.01716\n",
      "Epoch 43/50   -   loss: 0.01788   -   val_loss: 0.01718\n",
      "Epoch 44/50   -   loss: 0.01781   -   val_loss: 0.01715\n",
      "Epoch 45/50   -   loss: 0.01769   -   val_loss: 0.01722\n",
      "Epoch 46/50   -   loss: 0.01763   -   val_loss: 0.01719\n",
      "Epoch 47/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 48/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 49/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 7\n",
      "Epoch 1/50   -   loss: 0.26642   -   val_loss: 0.04368\n",
      "Epoch 2/50   -   loss: 0.03347   -   val_loss: 0.02373\n",
      "Epoch 3/50   -   loss: 0.02550   -   val_loss: 0.01980\n",
      "Epoch 4/50   -   loss: 0.02329   -   val_loss: 0.01819\n",
      "Epoch 5/50   -   loss: 0.02220   -   val_loss: 0.01747\n",
      "Epoch 6/50   -   loss: 0.02154   -   val_loss: 0.01711\n",
      "Epoch 7/50   -   loss: 0.02129   -   val_loss: 0.01673\n",
      "Epoch 8/50   -   loss: 0.02097   -   val_loss: 0.01664\n",
      "Epoch 9/50   -   loss: 0.02077   -   val_loss: 0.01643\n",
      "Epoch 10/50   -   loss: 0.02077   -   val_loss: 0.01647\n",
      "Epoch 11/50   -   loss: 0.02079   -   val_loss: 0.01637\n",
      "Epoch 12/50   -   loss: 0.02043   -   val_loss: 0.01646\n",
      "Epoch 13/50   -   loss: 0.02031   -   val_loss: 0.01647\n",
      "Epoch 14/50   -   loss: 0.02032   -   val_loss: 0.01674\n",
      "Epoch 15/50   -   loss: 0.02050   -   val_loss: 0.01637\n",
      "Epoch 16/50   -   loss: 0.02022   -   val_loss: 0.01637\n",
      "Epoch 17/50   -   loss: 0.02015   -   val_loss: 0.01659\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 18/50   -   loss: 0.01962   -   val_loss: 0.01609\n",
      "Epoch 19/50   -   loss: 0.01936   -   val_loss: 0.01609\n",
      "Epoch 20/50   -   loss: 0.01923   -   val_loss: 0.01614\n",
      "Epoch 21/50   -   loss: 0.01910   -   val_loss: 0.01610\n",
      "Epoch 22/50   -   loss: 0.01902   -   val_loss: 0.01612\n",
      "Epoch 23/50   -   loss: 0.01886   -   val_loss: 0.01615\n",
      "Epoch 24/50   -   loss: 0.01881   -   val_loss: 0.01609\n",
      "Epoch 25/50   -   loss: 0.01870   -   val_loss: 0.01605\n",
      "Epoch 26/50   -   loss: 0.01858   -   val_loss: 0.01616\n",
      "Epoch 27/50   -   loss: 0.01848   -   val_loss: 0.01617\n",
      "Epoch 28/50   -   loss: 0.01839   -   val_loss: 0.01621\n",
      "Epoch 29/50   -   loss: 0.01826   -   val_loss: 0.01627\n",
      "Epoch 30/50   -   loss: 0.01819   -   val_loss: 0.01615\n",
      "Epoch 31/50   -   loss: 0.01806   -   val_loss: 0.01617\n",
      "Epoch 32/50   -   loss: 0.01795   -   val_loss: 0.01616\n",
      "Epoch 33/50   -   loss: 0.01788   -   val_loss: 0.01618\n",
      "Epoch 34/50   -   loss: 0.01776   -   val_loss: 0.01616\n",
      "Epoch 35/50   -   loss: 0.01765   -   val_loss: 0.01618\n",
      "Epoch 36/50   -   loss: 0.01749   -   val_loss: 0.01620\n",
      "Epoch 37/50   -   loss: 0.01744   -   val_loss: 0.01626\n",
      "Epoch 38/50   -   loss: 0.01729   -   val_loss: 0.01616\n",
      "Epoch 39/50   -   loss: 0.01725   -   val_loss: 0.01629\n",
      "Epoch 40/50   -   loss: 0.01709   -   val_loss: 0.01632\n",
      "Epoch 41/50   -   loss: 0.01702   -   val_loss: 0.01622\n",
      "Epoch 42/50   -   loss: 0.01690   -   val_loss: 0.01623\n",
      "Epoch 43/50   -   loss: 0.01679   -   val_loss: 0.01627\n",
      "Epoch 44/50   -   loss: 0.01671   -   val_loss: 0.01638\n",
      "Epoch 45/50   -   loss: 0.01660   -   val_loss: 0.01636\n",
      "Epoch 46/50   -   loss: 0.01655   -   val_loss: 0.01624\n",
      "Epoch 47/50   -   loss: 0.01641   -   val_loss: 0.01653\n",
      "Epoch 48/50   -   loss: 0.01633   -   val_loss: 0.01643\n",
      "Epoch 49/50   -   loss: 0.01622   -   val_loss: 0.01637\n",
      "Epoch 50/50   -   loss: 0.01617   -   val_loss: 0.01650\n",
      "Train seed 1\n",
      "Train fold 1\n",
      "Epoch 1/50   -   loss: 0.26563   -   val_loss: 0.04516\n",
      "Epoch 2/50   -   loss: 0.03345   -   val_loss: 0.02452\n",
      "Epoch 3/50   -   loss: 0.02555   -   val_loss: 0.02065\n",
      "Epoch 4/50   -   loss: 0.02324   -   val_loss: 0.01921\n",
      "Epoch 5/50   -   loss: 0.02211   -   val_loss: 0.01833\n",
      "Epoch 6/50   -   loss: 0.02149   -   val_loss: 0.01790\n",
      "Epoch 7/50   -   loss: 0.02128   -   val_loss: 0.01842\n",
      "Epoch 8/50   -   loss: 0.02127   -   val_loss: 0.01758\n",
      "Epoch 9/50   -   loss: 0.02069   -   val_loss: 0.02125\n",
      "Epoch 10/50   -   loss: 0.02052   -   val_loss: 0.01731\n",
      "Epoch 11/50   -   loss: 0.02039   -   val_loss: 0.01750\n",
      "Epoch 12/50   -   loss: 0.02027   -   val_loss: 0.01721\n",
      "Epoch 13/50   -   loss: 0.02027   -   val_loss: 0.01732\n",
      "Epoch 14/50   -   loss: 0.02025   -   val_loss: 0.01742\n",
      "Epoch 15/50   -   loss: 0.02017   -   val_loss: 0.01727\n",
      "Epoch 16/50   -   loss: 0.02010   -   val_loss: 0.01885\n",
      "Epoch 17/50   -   loss: 0.02017   -   val_loss: 0.01717\n",
      "Epoch 18/50   -   loss: 0.01999   -   val_loss: 0.01720\n",
      "Epoch 19/50   -   loss: 0.01999   -   val_loss: 0.01720\n",
      "Epoch 20/50   -   loss: 0.01997   -   val_loss: 0.01735\n",
      "Epoch 21/50   -   loss: 0.02002   -   val_loss: 0.01711\n",
      "Epoch 22/50   -   loss: 0.01998   -   val_loss: 0.01721\n",
      "Epoch 23/50   -   loss: 0.01991   -   val_loss: 0.01708\n",
      "Epoch 24/50   -   loss: 0.01991   -   val_loss: 0.01709\n",
      "Epoch 25/50   -   loss: 0.01994   -   val_loss: 0.01708\n",
      "Epoch 26/50   -   loss: 0.01992   -   val_loss: 0.01704\n",
      "Epoch 27/50   -   loss: 0.01990   -   val_loss: 0.01704\n",
      "Epoch 28/50   -   loss: 0.01995   -   val_loss: 0.01701\n",
      "Epoch 29/50   -   loss: 0.01990   -   val_loss: 0.01706\n",
      "Epoch 30/50   -   loss: 0.01987   -   val_loss: 0.01711\n",
      "Epoch 31/50   -   loss: 0.01988   -   val_loss: 0.01719\n",
      "Epoch 32/50   -   loss: 0.01986   -   val_loss: 0.01712\n",
      "Epoch 33/50   -   loss: 0.01981   -   val_loss: 0.01729\n",
      "Epoch 34/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 35/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 36/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 37/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 38/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 39/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 40/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 41/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 42/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 43/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 44/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 45/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 46/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 47/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 48/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 49/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 2\n",
      "Epoch 1/50   -   loss: 0.26846   -   val_loss: 0.04213\n",
      "Epoch 2/50   -   loss: 0.03361   -   val_loss: 0.02361\n",
      "Epoch 3/50   -   loss: 0.02558   -   val_loss: 0.02005\n",
      "Epoch 4/50   -   loss: 0.02341   -   val_loss: 0.01868\n",
      "Epoch 5/50   -   loss: 0.02224   -   val_loss: 0.01794\n",
      "Epoch 6/50   -   loss: 0.02157   -   val_loss: 0.01766\n",
      "Epoch 7/50   -   loss: 0.02117   -   val_loss: 0.01754\n",
      "Epoch 8/50   -   loss: 0.02107   -   val_loss: 0.01723\n",
      "Epoch 9/50   -   loss: 0.02076   -   val_loss: 0.01721\n",
      "Epoch 10/50   -   loss: 0.02067   -   val_loss: 0.01722\n",
      "Epoch 11/50   -   loss: 0.02041   -   val_loss: 0.01702\n",
      "Epoch 12/50   -   loss: 0.02032   -   val_loss: 0.01700\n",
      "Epoch 13/50   -   loss: 0.02029   -   val_loss: 0.01708\n",
      "Epoch 14/50   -   loss: 0.02083   -   val_loss: 0.01695\n",
      "Epoch 15/50   -   loss: 0.02030   -   val_loss: 0.01698\n",
      "Epoch 16/50   -   loss: 0.02014   -   val_loss: 0.01697\n",
      "Epoch 17/50   -   loss: 0.02011   -   val_loss: 0.01694\n",
      "Epoch 18/50   -   loss: 0.02007   -   val_loss: 0.01701\n",
      "Epoch 19/50   -   loss: 0.02006   -   val_loss: 0.01724\n",
      "Epoch 20/50   -   loss: 0.02005   -   val_loss: 0.01704\n",
      "Epoch 21/50   -   loss: 0.02009   -   val_loss: 0.01686\n",
      "Epoch 22/50   -   loss: 0.01999   -   val_loss: 0.01693\n",
      "Epoch 23/50   -   loss: 0.01992   -   val_loss: 0.01694\n",
      "Epoch 24/50   -   loss: 0.01994   -   val_loss: 0.01700\n",
      "Epoch 25/50   -   loss: 0.01998   -   val_loss: 0.01720\n",
      "Epoch 26/50   -   loss: 0.01988   -   val_loss: 0.01691\n",
      "Epoch 27/50   -   loss: 0.01993   -   val_loss: 0.01700\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 28/50   -   loss: 0.01941   -   val_loss: 0.01676\n",
      "Epoch 29/50   -   loss: 0.01914   -   val_loss: 0.01672\n",
      "Epoch 30/50   -   loss: 0.01901   -   val_loss: 0.01673\n",
      "Epoch 31/50   -   loss: 0.01890   -   val_loss: 0.01670\n",
      "Epoch 32/50   -   loss: 0.01875   -   val_loss: 0.01671\n",
      "Epoch 33/50   -   loss: 0.01867   -   val_loss: 0.01674\n",
      "Epoch 34/50   -   loss: 0.01853   -   val_loss: 0.01678\n",
      "Epoch 35/50   -   loss: 0.01850   -   val_loss: 0.01672\n",
      "Epoch 36/50   -   loss: 0.01835   -   val_loss: 0.01674\n",
      "Epoch 37/50   -   loss: 0.01831   -   val_loss: 0.01674\n",
      "Epoch 38/50   -   loss: 0.01820   -   val_loss: 0.01672\n",
      "Epoch 39/50   -   loss: 0.01809   -   val_loss: 0.01676\n",
      "Epoch 40/50   -   loss: 0.01803   -   val_loss: 0.01678\n",
      "Epoch 41/50   -   loss: 0.01792   -   val_loss: 0.01680\n",
      "Epoch 42/50   -   loss: 0.01782   -   val_loss: 0.01680\n",
      "Epoch 43/50   -   loss: 0.01774   -   val_loss: 0.01683\n",
      "Epoch 44/50   -   loss: 0.01763   -   val_loss: 0.01680\n",
      "Epoch 45/50   -   loss: 0.01759   -   val_loss: 0.01686\n",
      "Epoch 46/50   -   loss: 0.01744   -   val_loss: 0.01683\n",
      "Epoch 47/50   -   loss: 0.01735   -   val_loss: 0.01688\n",
      "Epoch 48/50   -   loss: 0.01732   -   val_loss: 0.01692\n",
      "Epoch 49/50   -   loss: 0.01726   -   val_loss: 0.01693\n",
      "Epoch 50/50   -   loss: 0.01710   -   val_loss: 0.01699\n",
      "Train fold 3\n",
      "Epoch 1/50   -   loss: 0.26571   -   val_loss: 0.04023\n",
      "Epoch 2/50   -   loss: 0.03332   -   val_loss: 0.02444\n",
      "Epoch 3/50   -   loss: 0.02543   -   val_loss: 0.02074\n",
      "Epoch 4/50   -   loss: 0.02315   -   val_loss: 0.01914\n",
      "Epoch 5/50   -   loss: 0.02213   -   val_loss: 0.01858\n",
      "Epoch 6/50   -   loss: 0.02148   -   val_loss: 0.01840\n",
      "Epoch 7/50   -   loss: 0.02117   -   val_loss: 0.01797\n",
      "Epoch 8/50   -   loss: 0.02074   -   val_loss: 0.01789\n",
      "Epoch 9/50   -   loss: 0.02056   -   val_loss: 0.01767\n",
      "Epoch 10/50   -   loss: 0.02048   -   val_loss: 0.01765\n",
      "Epoch 11/50   -   loss: 0.02045   -   val_loss: 0.01777\n",
      "Epoch 12/50   -   loss: 0.02029   -   val_loss: 0.01742\n",
      "Epoch 13/50   -   loss: 0.02016   -   val_loss: 0.01748\n",
      "Epoch 14/50   -   loss: 0.02004   -   val_loss: 0.01755\n",
      "Epoch 15/50   -   loss: 0.02004   -   val_loss: 0.01749\n",
      "Epoch 16/50   -   loss: 0.02001   -   val_loss: 0.01756\n",
      "Epoch 17/50   -   loss: 0.02001   -   val_loss: 0.01748\n",
      "Epoch 18/50   -   loss: 0.02000   -   val_loss: 0.01753\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 19/50   -   loss: 0.01941   -   val_loss: 0.01724\n",
      "Epoch 20/50   -   loss: 0.01914   -   val_loss: 0.01724\n",
      "Epoch 21/50   -   loss: 0.01902   -   val_loss: 0.01720\n",
      "Epoch 22/50   -   loss: 0.01884   -   val_loss: 0.01719\n",
      "Epoch 23/50   -   loss: 0.01875   -   val_loss: 0.01724\n",
      "Epoch 24/50   -   loss: 0.01861   -   val_loss: 0.01722\n",
      "Epoch 25/50   -   loss: 0.01851   -   val_loss: 0.01728\n",
      "Epoch 26/50   -   loss: 0.01840   -   val_loss: 0.01729\n",
      "Epoch 27/50   -   loss: 0.01830   -   val_loss: 0.01729\n",
      "Epoch 28/50   -   loss: 0.01818   -   val_loss: 0.01731\n",
      "Epoch 29/50   -   loss: 0.01807   -   val_loss: 0.01725\n",
      "Epoch 30/50   -   loss: 0.01795   -   val_loss: 0.01733\n",
      "Epoch 31/50   -   loss: 0.01781   -   val_loss: 0.01734\n",
      "Epoch 32/50   -   loss: 0.01771   -   val_loss: 0.01731\n",
      "Epoch 33/50   -   loss: 0.01761   -   val_loss: 0.01737\n",
      "Epoch 34/50   -   loss: 0.01749   -   val_loss: 0.01737\n",
      "Epoch 35/50   -   loss: 0.01740   -   val_loss: 0.01746\n",
      "Epoch 36/50   -   loss: 0.01728   -   val_loss: 0.01741\n",
      "Epoch 37/50   -   loss: 0.01712   -   val_loss: 0.01752\n",
      "Epoch 38/50   -   loss: 0.01702   -   val_loss: 0.01748\n",
      "Epoch 39/50   -   loss: 0.01691   -   val_loss: 0.01746\n",
      "Epoch 40/50   -   loss: 0.01681   -   val_loss: 0.01746\n",
      "Epoch 41/50   -   loss: 0.01670   -   val_loss: 0.01764\n",
      "Epoch 42/50   -   loss: 0.01660   -   val_loss: 0.01758\n",
      "Epoch 43/50   -   loss: 0.01646   -   val_loss: 0.01750\n",
      "Epoch 44/50   -   loss: 0.01644   -   val_loss: 0.01757\n",
      "Epoch 45/50   -   loss: 0.01624   -   val_loss: 0.01757\n",
      "Epoch 46/50   -   loss: 0.01620   -   val_loss: 0.01760\n",
      "Epoch 47/50   -   loss: 0.01609   -   val_loss: 0.01766\n",
      "Epoch 48/50   -   loss: 0.01599   -   val_loss: 0.01769\n",
      "Epoch 49/50   -   loss: 0.01592   -   val_loss: 0.01773\n",
      "Epoch 50/50   -   loss: 0.01580   -   val_loss: 0.01763\n",
      "Train fold 4\n",
      "Epoch 1/50   -   loss: 0.26650   -   val_loss: 0.04127\n",
      "Epoch 2/50   -   loss: 0.03376   -   val_loss: 0.02367\n",
      "Epoch 3/50   -   loss: 0.02553   -   val_loss: 0.02033\n",
      "Epoch 4/50   -   loss: 0.02335   -   val_loss: 0.01884\n",
      "Epoch 5/50   -   loss: 0.02222   -   val_loss: 0.01808\n",
      "Epoch 6/50   -   loss: 0.02158   -   val_loss: 0.01766\n",
      "Epoch 7/50   -   loss: 0.02121   -   val_loss: 0.01733\n",
      "Epoch 8/50   -   loss: 0.02102   -   val_loss: 0.01716\n",
      "Epoch 9/50   -   loss: 0.02079   -   val_loss: 0.01721\n",
      "Epoch 10/50   -   loss: 0.02069   -   val_loss: 0.01688\n",
      "Epoch 11/50   -   loss: 0.02058   -   val_loss: 0.01682\n",
      "Epoch 12/50   -   loss: 0.02059   -   val_loss: 0.01713\n",
      "Epoch 13/50   -   loss: 0.02052   -   val_loss: 0.01664\n",
      "Epoch 14/50   -   loss: 0.02029   -   val_loss: 0.01672\n",
      "Epoch 15/50   -   loss: 0.02016   -   val_loss: 0.01668\n",
      "Epoch 16/50   -   loss: 0.02012   -   val_loss: 0.01673\n",
      "Epoch 17/50   -   loss: 0.02022   -   val_loss: 0.01661\n",
      "Epoch 18/50   -   loss: 0.02016   -   val_loss: 0.01661\n",
      "Epoch 19/50   -   loss: 0.02012   -   val_loss: 0.01653\n",
      "Epoch 20/50   -   loss: 0.02006   -   val_loss: 0.01652\n",
      "Epoch 21/50   -   loss: 0.02008   -   val_loss: 0.01659\n",
      "Epoch 22/50   -   loss: 0.02005   -   val_loss: 0.01665\n",
      "Epoch 23/50   -   loss: 0.02001   -   val_loss: 0.01661\n",
      "Epoch 24/50   -   loss: 0.01999   -   val_loss: 0.01674\n",
      "Epoch 25/50   -   loss: 0.01995   -   val_loss: 0.01669\n",
      "Epoch 26/50   -   loss: 0.02007   -   val_loss: 0.01654\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 27/50   -   loss: 0.01947   -   val_loss: 0.01631\n",
      "Epoch 28/50   -   loss: 0.01925   -   val_loss: 0.01633\n",
      "Epoch 29/50   -   loss: 0.01908   -   val_loss: 0.01629\n",
      "Epoch 30/50   -   loss: 0.01895   -   val_loss: 0.01625\n",
      "Epoch 31/50   -   loss: 0.01889   -   val_loss: 0.01631\n",
      "Epoch 32/50   -   loss: 0.01872   -   val_loss: 0.01626\n",
      "Epoch 33/50   -   loss: 0.01865   -   val_loss: 0.01627\n",
      "Epoch 34/50   -   loss: 0.01858   -   val_loss: 0.01629\n",
      "Epoch 35/50   -   loss: 0.01846   -   val_loss: 0.01633\n",
      "Epoch 36/50   -   loss: 0.01837   -   val_loss: 0.01635\n",
      "Epoch 37/50   -   loss: 0.01832   -   val_loss: 0.01632\n",
      "Epoch 38/50   -   loss: 0.01821   -   val_loss: 0.01631\n",
      "Epoch 39/50   -   loss: 0.01815   -   val_loss: 0.01631\n",
      "Epoch 40/50   -   loss: 0.01808   -   val_loss: 0.01630\n",
      "Epoch 41/50   -   loss: 0.01793   -   val_loss: 0.01637\n",
      "Epoch 42/50   -   loss: 0.01782   -   val_loss: 0.01639\n",
      "Epoch 43/50   -   loss: 0.01776   -   val_loss: 0.01637\n",
      "Epoch 44/50   -   loss: 0.01760   -   val_loss: 0.01638\n",
      "Epoch 45/50   -   loss: 0.01754   -   val_loss: 0.01641\n",
      "Epoch 46/50   -   loss: 0.01749   -   val_loss: 0.01645\n",
      "Epoch 47/50   -   loss: 0.01741   -   val_loss: 0.01642\n",
      "Epoch 48/50   -   loss: 0.01731   -   val_loss: 0.01648\n",
      "Epoch 49/50   -   loss: 0.01720   -   val_loss: 0.01653\n",
      "Epoch 50/50   -   loss: 0.01717   -   val_loss: 0.01651\n",
      "Train fold 5\n",
      "Epoch 1/50   -   loss: 0.26842   -   val_loss: 0.04181\n",
      "Epoch 2/50   -   loss: 0.03368   -   val_loss: 0.02388\n",
      "Epoch 3/50   -   loss: 0.02527   -   val_loss: 0.02026\n",
      "Epoch 4/50   -   loss: 0.02320   -   val_loss: 0.01900\n",
      "Epoch 5/50   -   loss: 0.02208   -   val_loss: 0.01829\n",
      "Epoch 6/50   -   loss: 0.02142   -   val_loss: 0.01799\n",
      "Epoch 7/50   -   loss: 0.02103   -   val_loss: 0.01778\n",
      "Epoch 8/50   -   loss: 0.02084   -   val_loss: 0.01767\n",
      "Epoch 9/50   -   loss: 0.02057   -   val_loss: 0.01737\n",
      "Epoch 10/50   -   loss: 0.02074   -   val_loss: 0.01782\n",
      "Epoch 11/50   -   loss: 0.02078   -   val_loss: 0.01733\n",
      "Epoch 12/50   -   loss: 0.02033   -   val_loss: 0.01728\n",
      "Epoch 13/50   -   loss: 0.02028   -   val_loss: 0.01726\n",
      "Epoch 14/50   -   loss: 0.02018   -   val_loss: 0.01727\n",
      "Epoch 15/50   -   loss: 0.02009   -   val_loss: 0.01733\n",
      "Epoch 16/50   -   loss: 0.02037   -   val_loss: 0.01732\n",
      "Epoch 17/50   -   loss: 0.02009   -   val_loss: 0.01714\n",
      "Epoch 18/50   -   loss: 0.02000   -   val_loss: 0.01720\n",
      "Epoch 19/50   -   loss: 0.01997   -   val_loss: 0.01720\n",
      "Epoch 20/50   -   loss: 0.01996   -   val_loss: 0.01719\n",
      "Epoch 21/50   -   loss: 0.01993   -   val_loss: 0.01721\n",
      "Epoch 22/50   -   loss: 0.02005   -   val_loss: 0.01719\n",
      "Epoch 23/50   -   loss: 0.01995   -   val_loss: 0.01719\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 24/50   -   loss: 0.01942   -   val_loss: 0.01696\n",
      "Epoch 25/50   -   loss: 0.01918   -   val_loss: 0.01694\n",
      "Epoch 26/50   -   loss: 0.01900   -   val_loss: 0.01697\n",
      "Epoch 27/50   -   loss: 0.01891   -   val_loss: 0.01697\n",
      "Epoch 28/50   -   loss: 0.01879   -   val_loss: 0.01696\n",
      "Epoch 29/50   -   loss: 0.01869   -   val_loss: 0.01701\n",
      "Epoch 30/50   -   loss: 0.01862   -   val_loss: 0.01697\n",
      "Epoch 31/50   -   loss: 0.01850   -   val_loss: 0.01701\n",
      "Epoch 32/50   -   loss: 0.01839   -   val_loss: 0.01698\n",
      "Epoch 33/50   -   loss: 0.01828   -   val_loss: 0.01700\n",
      "Epoch 34/50   -   loss: 0.01821   -   val_loss: 0.01693\n",
      "Epoch 35/50   -   loss: 0.01814   -   val_loss: 0.01697\n",
      "Epoch 36/50   -   loss: 0.01804   -   val_loss: 0.01704\n",
      "Epoch 37/50   -   loss: 0.01792   -   val_loss: 0.01704\n",
      "Epoch 38/50   -   loss: 0.01785   -   val_loss: 0.01705\n",
      "Epoch 39/50   -   loss: 0.01771   -   val_loss: 0.01706\n",
      "Epoch 40/50   -   loss: 0.01763   -   val_loss: 0.01711\n",
      "Epoch 41/50   -   loss: 0.01755   -   val_loss: 0.01712\n",
      "Epoch 42/50   -   loss: 0.01748   -   val_loss: 0.01713\n",
      "Epoch 43/50   -   loss: 0.01741   -   val_loss: 0.01712\n",
      "Epoch 44/50   -   loss: 0.01726   -   val_loss: 0.01720\n",
      "Epoch 45/50   -   loss: 0.01720   -   val_loss: 0.01719\n",
      "Epoch 46/50   -   loss: 0.01708   -   val_loss: 0.01720\n",
      "Epoch 47/50   -   loss: 0.01698   -   val_loss: 0.01725\n",
      "Epoch 48/50   -   loss: 0.01689   -   val_loss: 0.01725\n",
      "Epoch 49/50   -   loss: 0.01684   -   val_loss: 0.01727\n",
      "Epoch 50/50   -   loss: 0.01676   -   val_loss: 0.01733\n",
      "Train fold 6\n",
      "Epoch 1/50   -   loss: 0.26662   -   val_loss: 0.04311\n",
      "Epoch 2/50   -   loss: 0.03329   -   val_loss: 0.02445\n",
      "Epoch 3/50   -   loss: 0.02553   -   val_loss: 0.02052\n",
      "Epoch 4/50   -   loss: 0.02319   -   val_loss: 0.01932\n",
      "Epoch 5/50   -   loss: 0.02213   -   val_loss: 0.01839\n",
      "Epoch 6/50   -   loss: 0.02145   -   val_loss: 0.01804\n",
      "Epoch 7/50   -   loss: 0.02108   -   val_loss: 0.01769\n",
      "Epoch 8/50   -   loss: 0.02080   -   val_loss: 0.01761\n",
      "Epoch 9/50   -   loss: 0.02087   -   val_loss: 0.01749\n",
      "Epoch 10/50   -   loss: 0.02062   -   val_loss: 0.01737\n",
      "Epoch 11/50   -   loss: 0.02063   -   val_loss: 0.01743\n",
      "Epoch 12/50   -   loss: 0.02040   -   val_loss: 0.01740\n",
      "Epoch 13/50   -   loss: 0.02039   -   val_loss: 0.01742\n",
      "Epoch 14/50   -   loss: 0.02015   -   val_loss: 0.01732\n",
      "Epoch 15/50   -   loss: 0.02011   -   val_loss: 0.01775\n",
      "Epoch 16/50   -   loss: 0.02015   -   val_loss: 0.01734\n",
      "Epoch 17/50   -   loss: 0.02010   -   val_loss: 0.01728\n",
      "Epoch 18/50   -   loss: 0.02007   -   val_loss: 0.01740\n",
      "Epoch 19/50   -   loss: 0.02001   -   val_loss: 0.01720\n",
      "Epoch 20/50   -   loss: 0.02002   -   val_loss: 0.01730\n",
      "Epoch 21/50   -   loss: 0.01996   -   val_loss: 0.01727\n",
      "Epoch 22/50   -   loss: 0.01996   -   val_loss: 0.01721\n",
      "Epoch 23/50   -   loss: 0.01995   -   val_loss: 0.01711\n",
      "Epoch 24/50   -   loss: 0.01992   -   val_loss: 0.01724\n",
      "Epoch 25/50   -   loss: 0.01985   -   val_loss: 0.01723\n",
      "Epoch 26/50   -   loss: 0.01983   -   val_loss: 0.01725\n",
      "Epoch 27/50   -   loss: 0.01986   -   val_loss: 0.01732\n",
      "Epoch 28/50   -   loss: 0.01985   -   val_loss: 0.01724\n",
      "Epoch 29/50   -   loss: 0.01988   -   val_loss: 0.01724\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 30/50   -   loss: 0.01933   -   val_loss: 0.01701\n",
      "Epoch 31/50   -   loss: 0.01911   -   val_loss: 0.01705\n",
      "Epoch 32/50   -   loss: 0.01892   -   val_loss: 0.01704\n",
      "Epoch 33/50   -   loss: 0.01884   -   val_loss: 0.01705\n",
      "Epoch 34/50   -   loss: 0.01868   -   val_loss: 0.01704\n",
      "Epoch 35/50   -   loss: 0.01858   -   val_loss: 0.01709\n",
      "Epoch 36/50   -   loss: 0.01851   -   val_loss: 0.01710\n",
      "Epoch 37/50   -   loss: 0.01840   -   val_loss: 0.01712\n",
      "Epoch 38/50   -   loss: 0.01833   -   val_loss: 0.01711\n",
      "Epoch 39/50   -   loss: 0.01826   -   val_loss: 0.01720\n",
      "Epoch 40/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 41/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 42/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 43/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 44/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 45/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 46/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 47/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 48/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 49/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 7\n",
      "Epoch 1/50   -   loss: 0.26659   -   val_loss: 0.04110\n",
      "Epoch 2/50   -   loss: 0.03335   -   val_loss: 0.02410\n",
      "Epoch 3/50   -   loss: 0.02545   -   val_loss: 0.02017\n",
      "Epoch 4/50   -   loss: 0.02325   -   val_loss: 0.01835\n",
      "Epoch 5/50   -   loss: 0.02205   -   val_loss: 0.01744\n",
      "Epoch 6/50   -   loss: 0.02146   -   val_loss: 0.01694\n",
      "Epoch 7/50   -   loss: 0.02125   -   val_loss: 0.01685\n",
      "Epoch 8/50   -   loss: 0.02095   -   val_loss: 0.01649\n",
      "Epoch 9/50   -   loss: 0.02105   -   val_loss: 0.01659\n",
      "Epoch 10/50   -   loss: 0.02069   -   val_loss: 0.01646\n",
      "Epoch 11/50   -   loss: 0.02045   -   val_loss: 0.01641\n",
      "Epoch 12/50   -   loss: 0.02031   -   val_loss: 0.01641\n",
      "Epoch 13/50   -   loss: 0.02026   -   val_loss: 0.01645\n",
      "Epoch 14/50   -   loss: 0.02028   -   val_loss: 0.01617\n",
      "Epoch 15/50   -   loss: 0.02020   -   val_loss: 0.01635\n",
      "Epoch 16/50   -   loss: 0.02018   -   val_loss: 0.01635\n",
      "Epoch 17/50   -   loss: 0.02009   -   val_loss: 0.01615\n",
      "Epoch 18/50   -   loss: 0.02005   -   val_loss: 0.01641\n",
      "Epoch 19/50   -   loss: 0.02006   -   val_loss: 0.01606\n",
      "Epoch 20/50   -   loss: 0.02007   -   val_loss: 0.01617\n",
      "Epoch 21/50   -   loss: 0.01998   -   val_loss: 0.01626\n",
      "Epoch 22/50   -   loss: 0.01998   -   val_loss: 0.01632\n",
      "Epoch 23/50   -   loss: 0.02001   -   val_loss: 0.01632\n",
      "Epoch 24/50   -   loss: 0.02000   -   val_loss: 0.01627\n",
      "Epoch 25/50   -   loss: 0.01991   -   val_loss: 0.01635\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 26/50   -   loss: 0.01942   -   val_loss: 0.01603\n",
      "Epoch 27/50   -   loss: 0.01917   -   val_loss: 0.01607\n",
      "Epoch 28/50   -   loss: 0.01898   -   val_loss: 0.01606\n",
      "Epoch 29/50   -   loss: 0.01887   -   val_loss: 0.01601\n",
      "Epoch 30/50   -   loss: 0.01878   -   val_loss: 0.01601\n",
      "Epoch 31/50   -   loss: 0.01868   -   val_loss: 0.01594\n",
      "Epoch 32/50   -   loss: 0.01860   -   val_loss: 0.01600\n",
      "Epoch 33/50   -   loss: 0.01848   -   val_loss: 0.01606\n",
      "Epoch 34/50   -   loss: 0.01839   -   val_loss: 0.01595\n",
      "Epoch 35/50   -   loss: 0.01831   -   val_loss: 0.01599\n",
      "Epoch 36/50   -   loss: 0.01818   -   val_loss: 0.01608\n",
      "Epoch 37/50   -   loss: 0.01811   -   val_loss: 0.01601\n",
      "Epoch 38/50   -   loss: 0.01803   -   val_loss: 0.01596\n",
      "Epoch 39/50   -   loss: 0.01796   -   val_loss: 0.01599\n",
      "Epoch 40/50   -   loss: 0.01787   -   val_loss: 0.01606\n",
      "Epoch 41/50   -   loss: 0.01777   -   val_loss: 0.01603\n",
      "Epoch 42/50   -   loss: 0.01765   -   val_loss: 0.01618\n",
      "Epoch 43/50   -   loss: 0.01760   -   val_loss: 0.01608\n",
      "Epoch 44/50   -   loss: 0.01747   -   val_loss: 0.01612\n",
      "Epoch 45/50   -   loss: 0.01740   -   val_loss: 0.01618\n",
      "Epoch 46/50   -   loss: 0.01733   -   val_loss: 0.01623\n",
      "Epoch 47/50   -   loss: 0.01725   -   val_loss: 0.01621\n",
      "Epoch 48/50   -   loss: 0.01713   -   val_loss: 0.01620\n",
      "Epoch 49/50   -   loss: 0.01705   -   val_loss: 0.01621\n",
      "Epoch 50/50   -   loss: 0.01697   -   val_loss: 0.01630\n",
      "Train seed 2\n",
      "Train fold 1\n",
      "Epoch 1/50   -   loss: 0.26675   -   val_loss: 0.04125\n",
      "Epoch 2/50   -   loss: 0.03337   -   val_loss: 0.02411\n",
      "Epoch 3/50   -   loss: 0.02523   -   val_loss: 0.02038\n",
      "Epoch 4/50   -   loss: 0.02306   -   val_loss: 0.01910\n",
      "Epoch 5/50   -   loss: 0.02204   -   val_loss: 0.01824\n",
      "Epoch 6/50   -   loss: 0.02140   -   val_loss: 0.01790\n",
      "Epoch 7/50   -   loss: 0.02114   -   val_loss: 0.01766\n",
      "Epoch 8/50   -   loss: 0.02086   -   val_loss: 0.01781\n",
      "Epoch 9/50   -   loss: 0.02072   -   val_loss: 0.01749\n",
      "Epoch 10/50   -   loss: 0.02052   -   val_loss: 0.01737\n",
      "Epoch 11/50   -   loss: 0.02037   -   val_loss: 0.01726\n",
      "Epoch 12/50   -   loss: 0.02024   -   val_loss: 0.01729\n",
      "Epoch 13/50   -   loss: 0.02027   -   val_loss: 0.01712\n",
      "Epoch 14/50   -   loss: 0.02009   -   val_loss: 0.01718\n",
      "Epoch 15/50   -   loss: 0.02007   -   val_loss: 0.01750\n",
      "Epoch 16/50   -   loss: 0.02011   -   val_loss: 0.01722\n",
      "Epoch 17/50   -   loss: 0.02002   -   val_loss: 0.01714\n",
      "Epoch 18/50   -   loss: 0.02004   -   val_loss: 0.01723\n",
      "Epoch 19/50   -   loss: 0.02000   -   val_loss: 0.01711\n",
      "Epoch 20/50   -   loss: 0.02000   -   val_loss: 0.01719\n",
      "Epoch 21/50   -   loss: 0.01992   -   val_loss: 0.01729\n",
      "Epoch 22/50   -   loss: 0.01997   -   val_loss: 0.01714\n",
      "Epoch 23/50   -   loss: 0.01988   -   val_loss: 0.01704\n",
      "Epoch 24/50   -   loss: 0.01998   -   val_loss: 0.01720\n",
      "Epoch 25/50   -   loss: 0.01992   -   val_loss: 0.01714\n",
      "Epoch 26/50   -   loss: 0.01991   -   val_loss: 0.01709\n",
      "Epoch 27/50   -   loss: 0.01990   -   val_loss: 0.01719\n",
      "Epoch 28/50   -   loss: 0.01992   -   val_loss: 0.01723\n",
      "Epoch 29/50   -   loss: 0.01987   -   val_loss: 0.01720\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 30/50   -   loss: 0.01934   -   val_loss: 0.01694\n",
      "Epoch 31/50   -   loss: 0.01910   -   val_loss: 0.01688\n",
      "Epoch 32/50   -   loss: 0.01897   -   val_loss: 0.01686\n",
      "Epoch 33/50   -   loss: 0.01883   -   val_loss: 0.01685\n",
      "Epoch 34/50   -   loss: 0.01873   -   val_loss: 0.01685\n",
      "Epoch 35/50   -   loss: 0.01861   -   val_loss: 0.01690\n",
      "Epoch 36/50   -   loss: 0.01855   -   val_loss: 0.01683\n",
      "Epoch 37/50   -   loss: 0.01844   -   val_loss: 0.01689\n",
      "Epoch 38/50   -   loss: 0.01835   -   val_loss: 0.01690\n",
      "Epoch 39/50   -   loss: 0.01826   -   val_loss: 0.01689\n",
      "Epoch 40/50   -   loss: 0.01818   -   val_loss: 0.01688\n",
      "Epoch 41/50   -   loss: 0.01808   -   val_loss: 0.01691\n",
      "Epoch 42/50   -   loss: 0.01800   -   val_loss: 0.01690\n",
      "Epoch 43/50   -   loss: 0.01793   -   val_loss: 0.01693\n",
      "Epoch 44/50   -   loss: 0.01786   -   val_loss: 0.01695\n",
      "Epoch 45/50   -   loss: 0.01778   -   val_loss: 0.01696\n",
      "Epoch 46/50   -   loss: 0.01766   -   val_loss: 0.01692\n",
      "Epoch 47/50   -   loss: 0.01759   -   val_loss: 0.01701\n",
      "Epoch 48/50   -   loss: 0.01750   -   val_loss: 0.01689\n",
      "Epoch 49/50   -   loss: 0.01746   -   val_loss: 0.01694\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 2\n",
      "Epoch 1/50   -   loss: 0.26756   -   val_loss: 0.04237\n",
      "Epoch 2/50   -   loss: 0.03347   -   val_loss: 0.02490\n",
      "Epoch 3/50   -   loss: 0.02539   -   val_loss: 0.02006\n",
      "Epoch 4/50   -   loss: 0.02330   -   val_loss: 0.01891\n",
      "Epoch 5/50   -   loss: 0.02218   -   val_loss: 0.01794\n",
      "Epoch 6/50   -   loss: 0.02156   -   val_loss: 0.01767\n",
      "Epoch 7/50   -   loss: 0.02119   -   val_loss: 0.01738\n",
      "Epoch 8/50   -   loss: 0.02096   -   val_loss: 0.01742\n",
      "Epoch 9/50   -   loss: 0.02086   -   val_loss: 0.01729\n",
      "Epoch 10/50   -   loss: 0.02068   -   val_loss: 0.01715\n",
      "Epoch 11/50   -   loss: 0.02047   -   val_loss: 0.01695\n",
      "Epoch 12/50   -   loss: 0.02033   -   val_loss: 0.01709\n",
      "Epoch 13/50   -   loss: 0.02033   -   val_loss: 0.01718\n",
      "Epoch 14/50   -   loss: 0.02126   -   val_loss: 0.01710\n",
      "Epoch 15/50   -   loss: 0.02055   -   val_loss: 0.01707\n",
      "Epoch 16/50   -   loss: 0.02032   -   val_loss: 0.01685\n",
      "Epoch 17/50   -   loss: 0.02015   -   val_loss: 0.01685\n",
      "Epoch 18/50   -   loss: 0.02010   -   val_loss: 0.01697\n",
      "Epoch 19/50   -   loss: 0.02002   -   val_loss: 0.01685\n",
      "Epoch 20/50   -   loss: 0.02007   -   val_loss: 0.01690\n",
      "Epoch 21/50   -   loss: 0.01997   -   val_loss: 0.01697\n",
      "Epoch 22/50   -   loss: 0.01995   -   val_loss: 0.01686\n",
      "Epoch 23/50   -   loss: 0.01998   -   val_loss: 0.01690\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 24/50   -   loss: 0.01948   -   val_loss: 0.01670\n",
      "Epoch 25/50   -   loss: 0.01924   -   val_loss: 0.01668\n",
      "Epoch 26/50   -   loss: 0.01905   -   val_loss: 0.01671\n",
      "Epoch 27/50   -   loss: 0.01897   -   val_loss: 0.01671\n",
      "Epoch 28/50   -   loss: 0.01885   -   val_loss: 0.01675\n",
      "Epoch 29/50   -   loss: 0.01876   -   val_loss: 0.01670\n",
      "Epoch 30/50   -   loss: 0.01867   -   val_loss: 0.01676\n",
      "Epoch 31/50   -   loss: 0.01856   -   val_loss: 0.01674\n",
      "Epoch 32/50   -   loss: 0.01847   -   val_loss: 0.01679\n",
      "Epoch 33/50   -   loss: 0.01835   -   val_loss: 0.01679\n",
      "Epoch 34/50   -   loss: 0.01829   -   val_loss: 0.01680\n",
      "Epoch 35/50   -   loss: 0.01820   -   val_loss: 0.01681\n",
      "Epoch 36/50   -   loss: 0.01811   -   val_loss: 0.01685\n",
      "Epoch 37/50   -   loss: 0.01801   -   val_loss: 0.01685\n",
      "Epoch 38/50   -   loss: 0.01792   -   val_loss: 0.01685\n",
      "Epoch 39/50   -   loss: 0.01781   -   val_loss: 0.01682\n",
      "Epoch 40/50   -   loss: 0.01773   -   val_loss: 0.01689\n",
      "Epoch 41/50   -   loss: 0.01762   -   val_loss: 0.01687\n",
      "Epoch 42/50   -   loss: 0.01755   -   val_loss: 0.01689\n",
      "Epoch 43/50   -   loss: 0.01742   -   val_loss: 0.01694\n",
      "Epoch 44/50   -   loss: 0.01734   -   val_loss: 0.01696\n",
      "Epoch 45/50   -   loss: 0.01726   -   val_loss: 0.01693\n",
      "Epoch 46/50   -   loss: 0.01715   -   val_loss: 0.01702\n",
      "Epoch 47/50   -   loss: 0.01706   -   val_loss: 0.01697\n",
      "Epoch 48/50   -   loss: 0.01700   -   val_loss: 0.01697\n",
      "Epoch 49/50   -   loss: 0.01688   -   val_loss: 0.01702\n",
      "Epoch 50/50   -   loss: 0.01682   -   val_loss: 0.01702\n",
      "Train fold 3\n",
      "Epoch 1/50   -   loss: 0.26640   -   val_loss: 0.04079\n",
      "Epoch 2/50   -   loss: 0.03334   -   val_loss: 0.02422\n",
      "Epoch 3/50   -   loss: 0.02527   -   val_loss: 0.02051\n",
      "Epoch 4/50   -   loss: 0.02305   -   val_loss: 0.01924\n",
      "Epoch 5/50   -   loss: 0.02191   -   val_loss: 0.01880\n",
      "Epoch 6/50   -   loss: 0.02147   -   val_loss: 0.01817\n",
      "Epoch 7/50   -   loss: 0.02117   -   val_loss: 0.01797\n",
      "Epoch 8/50   -   loss: 0.02079   -   val_loss: 0.01781\n",
      "Epoch 9/50   -   loss: 0.02061   -   val_loss: 0.01769\n",
      "Epoch 10/50   -   loss: 0.02043   -   val_loss: 0.01773\n",
      "Epoch 11/50   -   loss: 0.02042   -   val_loss: 0.01776\n",
      "Epoch 12/50   -   loss: 0.02026   -   val_loss: 0.01739\n",
      "Epoch 13/50   -   loss: 0.02011   -   val_loss: 0.01970\n",
      "Epoch 14/50   -   loss: 0.02014   -   val_loss: 0.01751\n",
      "Epoch 15/50   -   loss: 0.02006   -   val_loss: 0.01778\n",
      "Epoch 16/50   -   loss: 0.02001   -   val_loss: 0.01791\n",
      "Epoch 17/50   -   loss: 0.02001   -   val_loss: 0.01831\n",
      "Epoch 18/50   -   loss: 0.01995   -   val_loss: 0.01737\n",
      "Epoch 19/50   -   loss: 0.01995   -   val_loss: 0.01742\n",
      "Epoch 20/50   -   loss: 0.01993   -   val_loss: 0.01743\n",
      "Epoch 21/50   -   loss: 0.01987   -   val_loss: 0.01756\n",
      "Epoch 22/50   -   loss: 0.01986   -   val_loss: 0.01735\n",
      "Epoch 23/50   -   loss: 0.01984   -   val_loss: 0.01746\n",
      "Epoch 24/50   -   loss: 0.01984   -   val_loss: 0.01760\n",
      "Epoch 25/50   -   loss: 0.01981   -   val_loss: 0.01758\n",
      "Epoch 26/50   -   loss: 0.01990   -   val_loss: 0.01732\n",
      "Epoch 27/50   -   loss: 0.01984   -   val_loss: 0.01749\n",
      "Epoch 28/50   -   loss: 0.01979   -   val_loss: 0.01752\n",
      "Epoch 29/50   -   loss: 0.01977   -   val_loss: 0.01753\n",
      "Epoch 30/50   -   loss: 0.01981   -   val_loss: 0.01747\n",
      "Epoch 31/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 32/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 33/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 34/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 35/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 36/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 37/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 38/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 39/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 40/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 41/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 42/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 43/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 44/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 45/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 46/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 47/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 48/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 49/50   -   loss:   nan   -   val_loss:   nan\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 4\n",
      "Epoch 1/50   -   loss: 0.26617   -   val_loss: 0.04283\n",
      "Epoch 2/50   -   loss: 0.03349   -   val_loss: 0.02386\n",
      "Epoch 3/50   -   loss: 0.02552   -   val_loss: 0.02035\n",
      "Epoch 4/50   -   loss: 0.02337   -   val_loss: 0.01890\n",
      "Epoch 5/50   -   loss: 0.02225   -   val_loss: 0.01793\n",
      "Epoch 6/50   -   loss: 0.02165   -   val_loss: 0.01740\n",
      "Epoch 7/50   -   loss: 0.02116   -   val_loss: 0.01720\n",
      "Epoch 8/50   -   loss: 0.02094   -   val_loss: 0.01715\n",
      "Epoch 9/50   -   loss: 0.02081   -   val_loss: 0.01755\n",
      "Epoch 10/50   -   loss: 0.02064   -   val_loss: 0.01696\n",
      "Epoch 11/50   -   loss: 0.02043   -   val_loss: 0.01690\n",
      "Epoch 12/50   -   loss: 0.02041   -   val_loss: 0.01676\n",
      "Epoch 13/50   -   loss: 0.02029   -   val_loss: 0.01731\n",
      "Epoch 14/50   -   loss: 0.02028   -   val_loss: 0.01676\n",
      "Epoch 15/50   -   loss: 0.02027   -   val_loss: 0.01685\n",
      "Epoch 16/50   -   loss: 0.02015   -   val_loss: 0.01677\n",
      "Epoch 17/50   -   loss: 0.02017   -   val_loss: 0.01666\n",
      "Epoch 18/50   -   loss: 0.02010   -   val_loss: 0.01661\n",
      "Epoch 19/50   -   loss: 0.02005   -   val_loss: 0.01672\n",
      "Epoch 20/50   -   loss: 0.02002   -   val_loss: 0.01659\n",
      "Epoch 21/50   -   loss: 0.02006   -   val_loss: 0.01657\n",
      "Epoch 22/50   -   loss: 0.02002   -   val_loss: 0.01656\n",
      "Epoch 23/50   -   loss: 0.02000   -   val_loss: 0.01658\n",
      "Epoch 24/50   -   loss: 0.01996   -   val_loss: 0.01659\n",
      "Epoch 25/50   -   loss: 0.02003   -   val_loss: 0.01680\n",
      "Epoch 26/50   -   loss: 0.02001   -   val_loss: 0.01672\n",
      "Epoch 27/50   -   loss: 0.01999   -   val_loss: 0.01673\n",
      "Epoch 28/50   -   loss: 0.01994   -   val_loss: 0.01656\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 29/50   -   loss: 0.01942   -   val_loss: 0.01636\n",
      "Epoch 30/50   -   loss: 0.01916   -   val_loss: 0.01635\n",
      "Epoch 31/50   -   loss: 0.01900   -   val_loss: 0.01635\n",
      "Epoch 32/50   -   loss: 0.01888   -   val_loss: 0.01638\n",
      "Epoch 33/50   -   loss: 0.01876   -   val_loss: 0.01638\n",
      "Epoch 34/50   -   loss: 0.01868   -   val_loss: 0.01636\n",
      "Epoch 35/50   -   loss: 0.01859   -   val_loss: 0.01639\n",
      "Epoch 36/50   -   loss: 0.01851   -   val_loss: 0.01636\n",
      "Epoch 37/50   -   loss: 0.01842   -   val_loss: 0.01637\n",
      "Epoch 38/50   -   loss: 0.01831   -   val_loss: 0.01635\n",
      "Epoch 39/50   -   loss: 0.01821   -   val_loss: 0.01636\n",
      "Epoch 40/50   -   loss: 0.01814   -   val_loss: 0.01638\n",
      "Epoch 41/50   -   loss: 0.01802   -   val_loss: 0.01633\n",
      "Epoch 42/50   -   loss: 0.01794   -   val_loss: 0.01637\n",
      "Epoch 43/50   -   loss: 0.01788   -   val_loss: 0.01642\n",
      "Epoch 44/50   -   loss: 0.01782   -   val_loss: 0.01640\n",
      "Epoch 45/50   -   loss: 0.01770   -   val_loss: 0.01646\n",
      "Epoch 46/50   -   loss: 0.01762   -   val_loss: 0.01642\n",
      "Epoch 47/50   -   loss: 0.01752   -   val_loss: 0.01639\n",
      "Epoch 48/50   -   loss: 0.01747   -   val_loss: 0.01648\n",
      "Epoch 49/50   -   loss: 0.01742   -   val_loss: 0.01649\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n",
      "Train fold 5\n",
      "Epoch 1/50   -   loss: 0.26758   -   val_loss: 0.04094\n",
      "Epoch 2/50   -   loss: 0.03337   -   val_loss: 0.02375\n",
      "Epoch 3/50   -   loss: 0.02543   -   val_loss: 0.02031\n",
      "Epoch 4/50   -   loss: 0.02329   -   val_loss: 0.01901\n",
      "Epoch 5/50   -   loss: 0.02208   -   val_loss: 0.01839\n",
      "Epoch 6/50   -   loss: 0.02152   -   val_loss: 0.01787\n",
      "Epoch 7/50   -   loss: 0.02120   -   val_loss: 0.01786\n",
      "Epoch 8/50   -   loss: 0.02104   -   val_loss: 0.01998\n",
      "Epoch 9/50   -   loss: 0.02215   -   val_loss: 0.01756\n",
      "Epoch 10/50   -   loss: 0.02118   -   val_loss: 0.01805\n",
      "Epoch 11/50   -   loss: 0.02081   -   val_loss: 0.01735\n",
      "Epoch 12/50   -   loss: 0.02047   -   val_loss: 0.01731\n",
      "Epoch 13/50   -   loss: 0.02041   -   val_loss: 0.01750\n",
      "Epoch 14/50   -   loss: 0.02030   -   val_loss: 0.01737\n",
      "Epoch 15/50   -   loss: 0.02024   -   val_loss: 0.01714\n",
      "Epoch 16/50   -   loss: 0.02017   -   val_loss: 0.01743\n",
      "Epoch 17/50   -   loss: 0.02012   -   val_loss: 0.01726\n",
      "Epoch 18/50   -   loss: 0.02012   -   val_loss: 0.01729\n",
      "Epoch 19/50   -   loss: 0.02010   -   val_loss: 0.01716\n",
      "Epoch 20/50   -   loss: 0.02004   -   val_loss: 0.01719\n",
      "Epoch 21/50   -   loss: 0.02009   -   val_loss: 0.01726\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 22/50   -   loss: 0.01958   -   val_loss: 0.01702\n",
      "Epoch 23/50   -   loss: 0.01930   -   val_loss: 0.01699\n",
      "Epoch 24/50   -   loss: 0.01914   -   val_loss: 0.01698\n",
      "Epoch 25/50   -   loss: 0.01904   -   val_loss: 0.01698\n",
      "Epoch 26/50   -   loss: 0.01894   -   val_loss: 0.01704\n",
      "Epoch 27/50   -   loss: 0.01880   -   val_loss: 0.01698\n",
      "Epoch 28/50   -   loss: 0.01870   -   val_loss: 0.01700\n",
      "Epoch 29/50   -   loss: 0.01862   -   val_loss: 0.01699\n",
      "Epoch 30/50   -   loss: 0.01849   -   val_loss: 0.01699\n",
      "Epoch 31/50   -   loss: 0.01842   -   val_loss: 0.01699\n",
      "Epoch 32/50   -   loss: 0.01832   -   val_loss: 0.01704\n",
      "Epoch 33/50   -   loss: 0.01821   -   val_loss: 0.01704\n",
      "Epoch 34/50   -   loss: 0.01814   -   val_loss: 0.01707\n",
      "Epoch 35/50   -   loss: 0.01799   -   val_loss: 0.01712\n",
      "Epoch 36/50   -   loss: 0.01789   -   val_loss: 0.01710\n",
      "Epoch 37/50   -   loss: 0.01780   -   val_loss: 0.01716\n",
      "Epoch 38/50   -   loss: 0.01768   -   val_loss: 0.01713\n",
      "Epoch 39/50   -   loss: 0.01757   -   val_loss: 0.01718\n",
      "Epoch 40/50   -   loss: 0.01746   -   val_loss: 0.01718\n",
      "Epoch 41/50   -   loss: 0.01739   -   val_loss: 0.01726\n",
      "Epoch 42/50   -   loss: 0.01726   -   val_loss: 0.01721\n",
      "Epoch 43/50   -   loss: 0.01718   -   val_loss: 0.01722\n",
      "Epoch 44/50   -   loss: 0.01709   -   val_loss: 0.01723\n",
      "Epoch 45/50   -   loss: 0.01697   -   val_loss: 0.01730\n",
      "Epoch 46/50   -   loss: 0.01688   -   val_loss: 0.01735\n",
      "Epoch 47/50   -   loss: 0.01681   -   val_loss: 0.01738\n",
      "Epoch 48/50   -   loss: 0.01667   -   val_loss: 0.01737\n",
      "Epoch 49/50   -   loss: 0.01658   -   val_loss: 0.01740\n",
      "Epoch 50/50   -   loss: 0.01647   -   val_loss: 0.01738\n",
      "Train fold 6\n",
      "Epoch 1/50   -   loss: 0.26703   -   val_loss: 0.04364\n",
      "Epoch 2/50   -   loss: 0.03329   -   val_loss: 0.02468\n",
      "Epoch 3/50   -   loss: 0.02540   -   val_loss: 0.02063\n",
      "Epoch 4/50   -   loss: 0.02317   -   val_loss: 0.01905\n",
      "Epoch 5/50   -   loss: 0.02204   -   val_loss: 0.01826\n",
      "Epoch 6/50   -   loss: 0.02158   -   val_loss: 0.01795\n",
      "Epoch 7/50   -   loss: 0.02117   -   val_loss: 0.01771\n",
      "Epoch 8/50   -   loss: 0.02087   -   val_loss: 0.01774\n",
      "Epoch 9/50   -   loss: 0.02080   -   val_loss: 0.01742\n",
      "Epoch 10/50   -   loss: 0.02067   -   val_loss: 0.01722\n",
      "Epoch 11/50   -   loss: 0.02054   -   val_loss: 0.01730\n",
      "Epoch 12/50   -   loss: 0.02034   -   val_loss: 0.01726\n",
      "Epoch 13/50   -   loss: 0.02028   -   val_loss: 0.01738\n",
      "Epoch 14/50   -   loss: 0.02031   -   val_loss: 0.01733\n",
      "Epoch 15/50   -   loss: 0.02025   -   val_loss: 0.01734\n",
      "Epoch 16/50   -   loss: 0.02003   -   val_loss: 0.01708\n",
      "Epoch 17/50   -   loss: 0.02002   -   val_loss: 0.01753\n",
      "Epoch 18/50   -   loss: 0.02005   -   val_loss: 0.01724\n",
      "Epoch 19/50   -   loss: 0.01993   -   val_loss: 0.01722\n",
      "Epoch 20/50   -   loss: 0.01989   -   val_loss: 0.01719\n",
      "Epoch 21/50   -   loss: 0.01991   -   val_loss: 0.01724\n",
      "Epoch 22/50   -   loss: 0.01984   -   val_loss: 0.01728\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 23/50   -   loss: 0.01940   -   val_loss: 0.01703\n",
      "Epoch 24/50   -   loss: 0.01915   -   val_loss: 0.01704\n",
      "Epoch 25/50   -   loss: 0.01896   -   val_loss: 0.01700\n",
      "Epoch 26/50   -   loss: 0.01882   -   val_loss: 0.01698\n",
      "Epoch 27/50   -   loss: 0.01872   -   val_loss: 0.01703\n",
      "Epoch 28/50   -   loss: 0.01862   -   val_loss: 0.01704\n",
      "Epoch 29/50   -   loss: 0.01853   -   val_loss: 0.01709\n",
      "Epoch 30/50   -   loss: 0.01838   -   val_loss: 0.01712\n",
      "Epoch 31/50   -   loss: 0.01834   -   val_loss: 0.01711\n",
      "Epoch 32/50   -   loss: 0.01826   -   val_loss: 0.01704\n",
      "Epoch 33/50   -   loss: 0.01816   -   val_loss: 0.01711\n",
      "Epoch 34/50   -   loss: 0.01806   -   val_loss: 0.01715\n",
      "Epoch 35/50   -   loss: 0.01795   -   val_loss: 0.01720\n",
      "Epoch 36/50   -   loss: 0.01788   -   val_loss: 0.01715\n",
      "Epoch 37/50   -   loss: 0.01778   -   val_loss: 0.01714\n",
      "Epoch 38/50   -   loss: 0.01767   -   val_loss: 0.01727\n",
      "Epoch 39/50   -   loss: 0.01760   -   val_loss: 0.01716\n",
      "Epoch 40/50   -   loss: 0.01745   -   val_loss: 0.01720\n",
      "Epoch 41/50   -   loss: 0.01739   -   val_loss: 0.01725\n",
      "Epoch 42/50   -   loss: 0.01730   -   val_loss: 0.01729\n",
      "Epoch 43/50   -   loss: 0.01724   -   val_loss: 0.01723\n",
      "Epoch 44/50   -   loss: 0.01707   -   val_loss: 0.01732\n",
      "Epoch 45/50   -   loss: 0.01699   -   val_loss: 0.01728\n",
      "Epoch 46/50   -   loss: 0.01696   -   val_loss: 0.01726\n",
      "Epoch 47/50   -   loss: 0.01684   -   val_loss: 0.01737\n",
      "Epoch 48/50   -   loss: 0.01678   -   val_loss: 0.01737\n",
      "Epoch 49/50   -   loss: 0.01669   -   val_loss: 0.01736\n",
      "Epoch 50/50   -   loss: 0.01655   -   val_loss: 0.01734\n",
      "Train fold 7\n",
      "Epoch 1/50   -   loss: 0.26517   -   val_loss: 0.04365\n",
      "Epoch 2/50   -   loss: 0.03327   -   val_loss: 0.02386\n",
      "Epoch 3/50   -   loss: 0.02544   -   val_loss: 0.01978\n",
      "Epoch 4/50   -   loss: 0.02310   -   val_loss: 0.01827\n",
      "Epoch 5/50   -   loss: 0.02203   -   val_loss: 0.01735\n",
      "Epoch 6/50   -   loss: 0.02150   -   val_loss: 0.01699\n",
      "Epoch 7/50   -   loss: 0.02118   -   val_loss: 0.01681\n",
      "Epoch 8/50   -   loss: 0.02100   -   val_loss: 0.01991\n",
      "Epoch 9/50   -   loss: 0.02137   -   val_loss: 0.01645\n",
      "Epoch 10/50   -   loss: 0.02079   -   val_loss: 0.01634\n",
      "Epoch 11/50   -   loss: 0.02046   -   val_loss: 0.01653\n",
      "Epoch 12/50   -   loss: 0.02030   -   val_loss: 0.01644\n",
      "Epoch 13/50   -   loss: 0.02062   -   val_loss: 0.01662\n",
      "Epoch 14/50   -   loss: 0.02063   -   val_loss: 0.01639\n",
      "Epoch 15/50   -   loss: 0.02031   -   val_loss: 0.01634\n",
      "Epoch 16/50   -   loss: 0.02022   -   val_loss: 0.01628\n",
      "Epoch 17/50   -   loss: 0.02011   -   val_loss: 0.01636\n",
      "Epoch 18/50   -   loss: 0.02012   -   val_loss: 0.01632\n",
      "Epoch 19/50   -   loss: 0.02006   -   val_loss: 0.01627\n",
      "Epoch 20/50   -   loss: 0.02006   -   val_loss: 0.01649\n",
      "Epoch 21/50   -   loss: 0.02006   -   val_loss: 0.01649\n",
      "Epoch 22/50   -   loss: 0.01995   -   val_loss: 0.01622\n",
      "Epoch 23/50   -   loss: 0.01992   -   val_loss: 0.01626\n",
      "Epoch 24/50   -   loss: 0.01999   -   val_loss: 0.01655\n",
      "Epoch 25/50   -   loss: 0.01995   -   val_loss: 0.01643\n",
      "Epoch 26/50   -   loss: 0.01996   -   val_loss: 0.01647\n",
      "Epoch 27/50   -   loss: 0.01989   -   val_loss: 0.01631\n",
      "Epoch 28/50   -   loss: 0.01992   -   val_loss: 0.01635\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 29/50   -   loss: 0.01938   -   val_loss: 0.01609\n",
      "Epoch 30/50   -   loss: 0.01912   -   val_loss: 0.01611\n",
      "Epoch 31/50   -   loss: 0.01899   -   val_loss: 0.01615\n",
      "Epoch 32/50   -   loss: 0.01886   -   val_loss: 0.01604\n",
      "Epoch 33/50   -   loss: 0.01875   -   val_loss: 0.01621\n",
      "Epoch 34/50   -   loss: 0.01867   -   val_loss: 0.01621\n",
      "Epoch 35/50   -   loss: 0.01856   -   val_loss: 0.01619\n",
      "Epoch 36/50   -   loss: 0.01845   -   val_loss: 0.01622\n",
      "Epoch 37/50   -   loss: 0.01836   -   val_loss: 0.01611\n",
      "Epoch 38/50   -   loss: 0.01826   -   val_loss: 0.01620\n",
      "Epoch 39/50   -   loss: 0.01820   -   val_loss: 0.01628\n",
      "Epoch 40/50   -   loss: 0.01814   -   val_loss: 0.01618\n",
      "Epoch 41/50   -   loss: 0.01801   -   val_loss: 0.01623\n",
      "Epoch 42/50   -   loss: 0.01793   -   val_loss: 0.01619\n",
      "Epoch 43/50   -   loss: 0.01787   -   val_loss: 0.01618\n",
      "Epoch 44/50   -   loss: 0.01775   -   val_loss: 0.01614\n",
      "Epoch 45/50   -   loss: 0.01766   -   val_loss: 0.01615\n",
      "Epoch 46/50   -   loss: 0.01760   -   val_loss: 0.01621\n",
      "Epoch 47/50   -   loss: 0.01749   -   val_loss: 0.01617\n",
      "Epoch 48/50   -   loss: 0.01743   -   val_loss: 0.01622\n",
      "Epoch 49/50   -   loss: 0.01735   -   val_loss: 0.01626\n",
      "Epoch 50/50   -   loss:   nan   -   val_loss:   nan\n"
     ]
    }
   ],
   "source": [
    "for seed in range(nstarts):\n",
    "    print(f'Train seed {seed}')\n",
    "    set_seed(seed)\n",
    "    \n",
    "    for n in range(nfolds):\n",
    "        print(f'Train fold {n+1}')\n",
    "        xtrain, xval = train[folds!=n], train[folds==n]\n",
    "        ytrain, yval = train_targets[folds!=n], train_targets[folds==n]\n",
    "        xtrain = np.concatenate([xtrain, train_pl], axis=0)\n",
    "        ytrain = np.concatenate([ytrain, train_targets_pl], axis=0)\n",
    "        \n",
    "        train_set = MoaDataset(xtrain, ytrain, top_feats)\n",
    "        val_set = MoaDataset(xval, yval, top_feats)\n",
    "        \n",
    "        dataloaders = {\n",
    "            'train': DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "            'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False)\n",
    "        }\n",
    "        \n",
    "        model = MoaModel(len(top_feats)).to(device)\n",
    "        checkpoint_path = f'repeat:{seed}_Fold:{n+1}.pt'\n",
    "        optimizer = optim.Adam(model.parameters(), weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, eps=1e-4, verbose=True)\n",
    "        best_loss = {'train': np.inf, 'val': np.inf}\n",
    "        \n",
    "        for epoch in range(nepochs):\n",
    "            epoch_loss = {'train': 0.0, 'val': 0.0}\n",
    "            \n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                \n",
    "                running_loss = 0.0\n",
    "                \n",
    "                for i, (x, y) in enumerate(dataloaders[phase]):\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    with torch.set_grad_enabled(phase=='train'):\n",
    "                        preds = model(x)\n",
    "                        \n",
    "                        if phase=='train':\n",
    "                            loss = trn_criterion(preds, y)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                        elif phase=='val':\n",
    "                            loss = val_criterion(preds[:, :ntargets], y[:, :ntargets])\n",
    "                    running_loss += loss.item() / len(dataloaders[phase])\n",
    "                \n",
    "                epoch_loss[phase] = running_loss\n",
    "            \n",
    "            print(\"Epoch {}/{}   -   loss: {:5.5f}   -   val_loss: {:5.5f}\".format(epoch+1, nepochs, epoch_loss['train'], epoch_loss['val']))\n",
    "            \n",
    "            scheduler.step(epoch_loss['val'])\n",
    "            \n",
    "            if epoch_loss['val'] < best_loss['val']:\n",
    "                best_loss = epoch_loss\n",
    "                torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:26:46.742073Z",
     "iopub.status.busy": "2020-11-24T19:26:46.740562Z",
     "iopub.status.idle": "2020-11-24T19:26:46.743944Z",
     "shell.execute_reply": "2020-11-24T19:26:46.744514Z"
    },
    "papermill": {
     "duration": 0.448441,
     "end_time": "2020-11-24T19:26:46.744667",
     "exception": false,
     "start_time": "2020-11-24T19:26:46.296226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof = np.zeros((len(train), nstarts, ntargets))\n",
    "oof_targets = np.zeros((len(train), ntargets))\n",
    "preds = np.zeros((len(test), ntargets))\n",
    "targets = targets[:ntargets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:26:47.631488Z",
     "iopub.status.busy": "2020-11-24T19:26:47.630107Z",
     "iopub.status.idle": "2020-11-24T19:26:47.632260Z",
     "shell.execute_reply": "2020-11-24T19:26:47.632817Z"
    },
    "papermill": {
     "duration": 0.450343,
     "end_time": "2020-11-24T19:26:47.632961",
     "exception": false,
     "start_time": "2020-11-24T19:26:47.182618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(targets):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:26:48.527725Z",
     "iopub.status.busy": "2020-11-24T19:26:48.522914Z",
     "iopub.status.idle": "2020-11-24T19:27:00.267438Z",
     "shell.execute_reply": "2020-11-24T19:27:00.268097Z"
    },
    "papermill": {
     "duration": 12.197848,
     "end_time": "2020-11-24T19:27:00.268290",
     "exception": false,
     "start_time": "2020-11-24T19:26:48.070442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for seed 0\n",
      "Score for this seed 0.01703\n",
      "Inference for seed 1\n",
      "Score for this seed 0.01702\n",
      "Inference for seed 2\n",
      "Score for this seed 0.01705\n",
      "Overall score is 0.01690\n"
     ]
    }
   ],
   "source": [
    "for seed in range(nstarts):\n",
    "    print(f\"Inference for seed {seed}\")\n",
    "    seed_targets = []\n",
    "    seed_oof = []\n",
    "    seed_preds = np.zeros((len(test), ntargets, nfolds))\n",
    "    \n",
    "    for n in range(nfolds):\n",
    "        xval, yval = train[folds==n], train_targets[folds==n]\n",
    "        fold_preds = []\n",
    "        \n",
    "        val_set = MoaDataset(xval, yval, top_feats)\n",
    "        test_set = MoaDataset(test, None, top_feats, mode='test')\n",
    "        \n",
    "        dataloaders = {\n",
    "            'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False),\n",
    "            'test': DataLoader(test_set, batch_size=val_batch_size, shuffle=False)\n",
    "        }\n",
    "        \n",
    "        checkpoint_path = f'repeat:{seed}_Fold:{n+1}.pt'\n",
    "        model = MoaModel(len(top_feats)).to(device)\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "        model.eval()\n",
    "        \n",
    "        for phase in ['val', 'test']:\n",
    "            for i, (x, y) in enumerate(dataloaders[phase]):\n",
    "                if phase == 'val':\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                elif phase == 'test':\n",
    "                    x = x.to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    batch_preds = model(x)\n",
    "                    batch_preds = batch_preds[:, :ntargets]\n",
    "                    \n",
    "                    if phase == 'val':\n",
    "                        seed_targets.append(y)\n",
    "                        seed_oof.append(batch_preds)\n",
    "                    elif phase == 'test':\n",
    "                        fold_preds.append(F.sigmoid(batch_preds))\n",
    "                    \n",
    "        fold_preds = torch.cat(fold_preds, dim=0).cpu().numpy()\n",
    "        seed_preds[:, :, n] = fold_preds\n",
    "        \n",
    "    seed_targets = torch.cat(seed_targets, dim=0).cpu().numpy()\n",
    "    seed_oof = F.sigmoid(torch.cat(seed_oof, dim=0)).cpu().numpy()\n",
    "    seed_preds = np.mean(seed_preds, axis=2)\n",
    "    \n",
    "    print(\"Score for this seed {:5.5f}\".format(mean_log_loss(seed_targets, seed_oof)))\n",
    "    oof_targets = seed_targets\n",
    "    oof[:, seed, :] = seed_oof\n",
    "    preds += seed_preds / nstarts\n",
    "\n",
    "oof = np.mean(oof, axis=1)\n",
    "print(\"Overall score is {:5.5f}\".format(mean_log_loss(oof_targets, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:27:01.158736Z",
     "iopub.status.busy": "2020-11-24T19:27:01.157453Z",
     "iopub.status.idle": "2020-11-24T19:27:01.202900Z",
     "shell.execute_reply": "2020-11-24T19:27:01.202208Z"
    },
    "papermill": {
     "duration": 0.492592,
     "end_time": "2020-11-24T19:27:01.203019",
     "exception": false,
     "start_time": "2020-11-24T19:27:00.710427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('multilabel_oof.npy', oof)\n",
    "np.save('multilabel_targets.npy', oof_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T19:27:02.227669Z",
     "iopub.status.busy": "2020-11-24T19:27:02.226186Z",
     "iopub.status.idle": "2020-11-24T19:27:05.132324Z",
     "shell.execute_reply": "2020-11-24T19:27:05.131239Z"
    },
    "papermill": {
     "duration": 3.485712,
     "end_time": "2020-11-24T19:27:05.132469",
     "exception": false,
     "start_time": "2020-11-24T19:27:01.646757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss[targets] = preds\n",
    "ss.loc[test_features['cp_type']=='ctl_vehicle', targets] = 0\n",
    "ss.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2499.301644,
   "end_time": "2020-11-24T19:27:06.632036",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-24T18:45:27.330392",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}