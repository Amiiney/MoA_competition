{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:10:29.939689Z",
     "iopub.status.busy": "2020-12-11T14:10:29.939083Z",
     "iopub.status.idle": "2020-12-11T14:10:30.783887Z",
     "shell.execute_reply": "2020-12-11T14:10:30.783144Z"
    },
    "papermill": {
     "duration": 0.870384,
     "end_time": "2020-12-11T14:10:30.784049",
     "exception": false,
     "start_time": "2020-12-11T14:10:29.913665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/rank-gauss\")\n",
    "from gauss_rank_scaler import GaussRankScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-12-11T14:10:30.830460Z",
     "iopub.status.busy": "2020-12-11T14:10:30.829646Z",
     "iopub.status.idle": "2020-12-11T14:10:59.929122Z",
     "shell.execute_reply": "2020-12-11T14:10:59.928536Z"
    },
    "papermill": {
     "duration": 29.125227,
     "end_time": "2020-12-11T14:10:59.929252",
     "exception": false,
     "start_time": "2020-12-11T14:10:30.804025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pytorchtabnetpretraining/pytorch_tabnet-2.0.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet==2.0.1) (0.23.2)\r\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet==2.0.1) (1.4.1)\r\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet==2.0.1) (4.45.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet==2.0.1) (1.18.5)\r\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-tabnet==2.0.1) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet==2.0.1) (2.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit_learn>0.21->pytorch-tabnet==2.0.1) (0.14.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.2->pytorch-tabnet==2.0.1) (0.18.2)\r\n",
      "Installing collected packages: pytorch-tabnet\r\n",
      "Successfully installed pytorch-tabnet-2.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/pytorchtabnetpretraining/pytorch_tabnet-2.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-11T14:10:59.980785Z",
     "iopub.status.busy": "2020-12-11T14:10:59.980088Z",
     "iopub.status.idle": "2020-12-11T14:11:01.407629Z",
     "shell.execute_reply": "2020-12-11T14:11:01.406723Z"
    },
    "papermill": {
     "duration": 1.456621,
     "end_time": "2020-12-11T14:11:01.407748",
     "exception": false,
     "start_time": "2020-12-11T14:10:59.951127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:01.462535Z",
     "iopub.status.busy": "2020-12-11T14:11:01.461864Z",
     "iopub.status.idle": "2020-12-11T14:11:11.069052Z",
     "shell.execute_reply": "2020-12-11T14:11:11.067738Z"
    },
    "papermill": {
     "duration": 9.639468,
     "end_time": "2020-12-11T14:11:11.069222",
     "exception": false,
     "start_time": "2020-12-11T14:11:01.429754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "drug_ids = pd.read_csv('../input/lish-moa/train_drug.csv')\n",
    "train_targets_noscore = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "folds = np.load('../input/fold-save/folds.npy')\n",
    "train_targets_pl = pd.read_csv('../input/sin-submission/submission.csv')\n",
    "train_features_pl = pd.read_csv('../input/test-public-moa/test_features.csv')\n",
    "\n",
    "ss = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:11.132224Z",
     "iopub.status.busy": "2020-12-11T14:11:11.131312Z",
     "iopub.status.idle": "2020-12-11T14:11:11.134259Z",
     "shell.execute_reply": "2020-12-11T14:11:11.134695Z"
    },
    "papermill": {
     "duration": 0.043163,
     "end_time": "2020-12-11T14:11:11.134835",
     "exception": false,
     "start_time": "2020-12-11T14:11:11.091672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:11.533778Z",
     "iopub.status.busy": "2020-12-11T14:11:11.532778Z",
     "iopub.status.idle": "2020-12-11T14:11:11.536058Z",
     "shell.execute_reply": "2020-12-11T14:11:11.535234Z"
    },
    "papermill": {
     "duration": 0.380047,
     "end_time": "2020-12-11T14:11:11.536168",
     "exception": false,
     "start_time": "2020-12-11T14:11:11.156121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nfolds = 7\n",
    "nstarts = 3\n",
    "nepochs = 200\n",
    "fold_seed = 42\n",
    "batch_size = 128\n",
    "val_batch_size = batch_size * 4\n",
    "ntargets = 206\n",
    "# targets = [col for col in train_targets.columns]\n",
    "val_criterion = nn.BCEWithLogitsLoss()\n",
    "trn_criterion = SmoothBCEwLogits(smoothing=0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "genes_comp = 80\n",
    "cells_comp = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:11.584459Z",
     "iopub.status.busy": "2020-12-11T14:11:11.582685Z",
     "iopub.status.idle": "2020-12-11T14:11:11.585160Z",
     "shell.execute_reply": "2020-12-11T14:11:11.585625Z"
    },
    "papermill": {
     "duration": 0.028071,
     "end_time": "2020-12-11T14:11:11.585749",
     "exception": false,
     "start_time": "2020-12-11T14:11:11.557678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:11.638412Z",
     "iopub.status.busy": "2020-12-11T14:11:11.637070Z",
     "iopub.status.idle": "2020-12-11T14:11:11.742021Z",
     "shell.execute_reply": "2020-12-11T14:11:11.741272Z"
    },
    "papermill": {
     "duration": 0.134688,
     "end_time": "2020-12-11T14:11:11.742156",
     "exception": false,
     "start_time": "2020-12-11T14:11:11.607468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "train = preprocess(train_features)\n",
    "test = preprocess(test_features)\n",
    "train_pl = preprocess(train_features_pl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:11.798905Z",
     "iopub.status.busy": "2020-12-11T14:11:11.797939Z",
     "iopub.status.idle": "2020-12-11T14:11:46.762061Z",
     "shell.execute_reply": "2020-12-11T14:11:46.763286Z"
    },
    "papermill": {
     "duration": 34.998954,
     "end_time": "2020-12-11T14:11:46.763494",
     "exception": false,
     "start_time": "2020-12-11T14:11:11.764540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantile(tr, te, feats):\n",
    "    data_all = pd.concat([tr, te], ignore_index = True)\n",
    "    scaler = GaussRankScaler()\n",
    "    data_all[feats] = scaler.fit_transform(data_all[feats])\n",
    "    \n",
    "    tr = data_all[:len(tr)]\n",
    "    te = data_all[len(tr):]\n",
    "    \n",
    "    return tr, te\n",
    "\n",
    "_, train_pl = quantile(train, train_pl, GENES)\n",
    "_, train_pl = quantile(_, train_pl, CELLS)\n",
    "train, test = quantile(train, test, GENES)\n",
    "train, test = quantile(train, test, CELLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:46.840224Z",
     "iopub.status.busy": "2020-12-11T14:11:46.839345Z",
     "iopub.status.idle": "2020-12-11T14:11:51.721480Z",
     "shell.execute_reply": "2020-12-11T14:11:51.720163Z"
    },
    "papermill": {
     "duration": 4.924117,
     "end_time": "2020-12-11T14:11:51.721605",
     "exception": false,
     "start_time": "2020-12-11T14:11:46.797488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca(tr, te, feats, n_components, group):\n",
    "    data_all = pd.concat([tr, te])\n",
    "    pca_transformer = PCA(n_components=n_components, random_state=42)\n",
    "    data_pca = pca_transformer.fit_transform(data_all[feats])\n",
    "    \n",
    "    if group == 'genes':\n",
    "        cols = [f'pca_G-{i}' for i in range(n_components)]\n",
    "    elif group == 'cells':\n",
    "        cols = [f'pca_C-{i}' for i in range(n_components)]\n",
    "    \n",
    "    data_all = pd.concat([data_all, pd.DataFrame(data_pca, columns=cols)], axis=1)\n",
    "    \n",
    "    tr = data_all[:len(tr)]\n",
    "    te = data_all[len(tr):]\n",
    "    \n",
    "    return tr, te\n",
    "\n",
    "_, train_pl = pca(train, train_pl, GENES, genes_comp, 'genes')\n",
    "_, train_pl = pca(_, train_pl, CELLS, cells_comp, 'cells')\n",
    "train, test = pca(train, test, GENES, genes_comp, 'genes')\n",
    "train, test = pca(train, test, CELLS, cells_comp, 'cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:51.787023Z",
     "iopub.status.busy": "2020-12-11T14:11:51.786144Z",
     "iopub.status.idle": "2020-12-11T14:11:51.815301Z",
     "shell.execute_reply": "2020-12-11T14:11:51.814750Z"
    },
    "papermill": {
     "duration": 0.07164,
     "end_time": "2020-12-11T14:11:51.815422",
     "exception": false,
     "start_time": "2020-12-11T14:11:51.743782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = train_targets.columns[1:]\n",
    "train_targets = train_targets.merge(drug_ids, on='sig_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:51.868624Z",
     "iopub.status.busy": "2020-12-11T14:11:51.867246Z",
     "iopub.status.idle": "2020-12-11T14:11:51.879943Z",
     "shell.execute_reply": "2020-12-11T14:11:51.879388Z"
    },
    "papermill": {
     "duration": 0.041841,
     "end_time": "2020-12-11T14:11:51.880073",
     "exception": false,
     "start_time": "2020-12-11T14:11:51.838232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pl = train_pl.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:51.933148Z",
     "iopub.status.busy": "2020-12-11T14:11:51.932317Z",
     "iopub.status.idle": "2020-12-11T14:11:52.343371Z",
     "shell.execute_reply": "2020-12-11T14:11:52.342206Z"
    },
    "papermill": {
     "duration": 0.440868,
     "end_time": "2020-12-11T14:11:52.343561",
     "exception": false,
     "start_time": "2020-12-11T14:11:51.902693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_targets = train_targets.loc[train['cp_type']==0].reset_index(drop=True)\n",
    "train_targets_pl = train_targets_pl.loc[train_pl['cp_type']==0].reset_index(drop=True)\n",
    "train = train.loc[train['cp_type']==0].reset_index(drop=True)\n",
    "train_pl = train_pl.loc[train_pl['cp_type']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:52.510389Z",
     "iopub.status.busy": "2020-12-11T14:11:52.507418Z",
     "iopub.status.idle": "2020-12-11T14:11:52.544209Z",
     "shell.execute_reply": "2020-12-11T14:11:52.543143Z"
    },
    "papermill": {
     "duration": 0.129118,
     "end_time": "2020-12-11T14:11:52.544362",
     "exception": false,
     "start_time": "2020-12-11T14:11:52.415244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:52.744389Z",
     "iopub.status.busy": "2020-12-11T14:11:52.743318Z",
     "iopub.status.idle": "2020-12-11T14:11:52.769221Z",
     "shell.execute_reply": "2020-12-11T14:11:52.766249Z"
    },
    "papermill": {
     "duration": 0.143747,
     "end_time": "2020-12-11T14:11:52.769394",
     "exception": false,
     "start_time": "2020-12-11T14:11:52.625647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       129\n",
       "2         3\n",
       "3         2\n",
       "4         3\n",
       "5        66\n",
       "6      2774\n",
       "7       196\n",
       "8         4\n",
       "11        4\n",
       "12       64\n",
       "13       25\n",
       "14        6\n",
       "18        3\n",
       "19        1\n",
       "178       1\n",
       "186       1\n",
       "194       1\n",
       "196       1\n",
       "202       1\n",
       "203       1\n",
       "246       1\n",
       "718       1\n",
       "Name: drug_id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets['fold'] = folds\n",
    "train_targets.drug_id.value_counts().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:52.927237Z",
     "iopub.status.busy": "2020-12-11T14:11:52.926318Z",
     "iopub.status.idle": "2020-12-11T14:11:52.944097Z",
     "shell.execute_reply": "2020-12-11T14:11:52.941294Z"
    },
    "papermill": {
     "duration": 0.099989,
     "end_time": "2020-12-11T14:11:52.944254",
     "exception": false,
     "start_time": "2020-12-11T14:11:52.844265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.044609Z",
     "iopub.status.busy": "2020-12-11T14:11:53.040801Z",
     "iopub.status.idle": "2020-12-11T14:11:53.139924Z",
     "shell.execute_reply": "2020-12-11T14:11:53.148195Z"
    },
    "papermill": {
     "duration": 0.153891,
     "end_time": "2020-12-11T14:11:53.148538",
     "exception": false,
     "start_time": "2020-12-11T14:11:52.994647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "top_feats = [  1,   2,   3,   4,   5,   6,   7,   9,  11,  14,  15,  16,  17,\n",
    "        18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  29,  30,  31,\n",
    "        32,  33,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  46,\n",
    "        47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  58,  59,  60,\n",
    "        61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
    "        74,  75,  76,  78,  79,  80,  81,  82,  83,  84,  86,  87,  88,\n",
    "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
    "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
    "       115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
    "       129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143,\n",
    "       144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
    "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
    "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
    "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197,\n",
    "       198, 199, 200, 202, 203, 204, 205, 206, 208, 209, 210, 211, 212,\n",
    "       213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226,\n",
    "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
    "       240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
    "       254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
    "       267, 268, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
    "       281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 294,\n",
    "       295, 296, 298, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
    "       310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
    "       324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
    "       337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
    "       350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362,\n",
    "       363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376, 377,\n",
    "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391,\n",
    "       392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404,\n",
    "       405, 406, 407, 408, 409, 411, 412, 413, 414, 415, 416, 417, 418,\n",
    "       419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
    "       432, 434, 435, 436, 437, 438, 439, 440, 442, 443, 444, 445, 446,\n",
    "       447, 448, 449, 450, 453, 454, 456, 457, 458, 459, 460, 461, 462,\n",
    "       463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
    "       476, 477, 478, 479, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
    "       490, 491, 492, 493, 494, 495, 496, 498, 500, 501, 502, 503, 505,\n",
    "       506, 507, 509, 510, 511, 512, 513, 514, 515, 518, 519, 520, 521,\n",
    "       522, 523, 524, 525, 526, 527, 528, 530, 531, 532, 534, 535, 536,\n",
    "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 549, 550, 551,\n",
    "       552, 554, 557, 559, 560, 561, 562, 565, 566, 567, 568, 569, 570,\n",
    "       571, 572, 573, 574, 575, 577, 578, 580, 581, 582, 583, 584, 585,\n",
    "       586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 599,\n",
    "       600, 601, 602, 606, 607, 608, 609, 611, 612, 613, 615, 616, 617,\n",
    "       618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
    "       631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 643, 644,\n",
    "       645, 646, 647, 648, 649, 650, 651, 652, 654, 655, 656, 658, 659,\n",
    "       660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672,\n",
    "       673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
    "       686, 687, 688, 689, 691, 692, 693, 694, 695, 696, 697, 699, 700,\n",
    "       701, 702, 704, 705, 707, 708, 709, 710, 711, 713, 714, 716, 717,\n",
    "       718, 720, 721, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732,\n",
    "       733, 734, 735, 737, 738, 739, 740, 742, 743, 744, 745, 746, 747,\n",
    "       748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 759, 760, 761,\n",
    "       762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774,\n",
    "       775, 776, 777, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788,\n",
    "       789, 790, 792, 793, 794, 795, 796, 797, 798, 800, 801, 802, 803,\n",
    "       804, 805, 806, 808, 809, 811, 813, 814, 815, 816, 817, 818, 819,\n",
    "       821, 822, 823, 825, 826, 827, 828, 829, 830, 831, 832, 834, 835,\n",
    "       837, 838, 839, 840, 841, 842, 845, 846, 847, 848, 850, 851, 852,\n",
    "       854, 855, 856, 858, 859, 860, 861, 862, 864, 866, 867, 868, 869,\n",
    "       870, 871, 872, 873, 874]\n",
    "print(len(top_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.323918Z",
     "iopub.status.busy": "2020-12-11T14:11:53.323036Z",
     "iopub.status.idle": "2020-12-11T14:11:53.327657Z",
     "shell.execute_reply": "2020-12-11T14:11:53.328785Z"
    },
    "papermill": {
     "duration": 0.085855,
     "end_time": "2020-12-11T14:11:53.329145",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.243290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add pca feature indices to feature indices\n",
    "pca_feats = [i for i in range(875, 875+genes_comp+cells_comp)]\n",
    "top_feats.extend(pca_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.431445Z",
     "iopub.status.busy": "2020-12-11T14:11:53.430561Z",
     "iopub.status.idle": "2020-12-11T14:11:53.432788Z",
     "shell.execute_reply": "2020-12-11T14:11:53.432157Z"
    },
    "papermill": {
     "duration": 0.048703,
     "end_time": "2020-12-11T14:11:53.432920",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.384217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = train_targets.fold.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.499177Z",
     "iopub.status.busy": "2020-12-11T14:11:53.497887Z",
     "iopub.status.idle": "2020-12-11T14:11:53.666669Z",
     "shell.execute_reply": "2020-12-11T14:11:53.666095Z"
    },
    "papermill": {
     "duration": 0.199417,
     "end_time": "2020-12-11T14:11:53.666776",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.467359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.values[:, top_feats]\n",
    "train_pl = train_pl.values[:, top_feats]\n",
    "test = test.values[:, top_feats]\n",
    "train_targets = train_targets[targets].values\n",
    "train_targets_pl = train_targets_pl[targets].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.724387Z",
     "iopub.status.busy": "2020-12-11T14:11:53.723665Z",
     "iopub.status.idle": "2020-12-11T14:11:53.727057Z",
     "shell.execute_reply": "2020-12-11T14:11:53.726451Z"
    },
    "papermill": {
     "duration": 0.035463,
     "end_time": "2020-12-11T14:11:53.727171",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.691708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof = np.zeros((len(train), nstarts, ntargets))\n",
    "oof_targets = np.zeros((len(train), ntargets))\n",
    "preds = np.zeros((len(test), ntargets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.783698Z",
     "iopub.status.busy": "2020-12-11T14:11:53.782897Z",
     "iopub.status.idle": "2020-12-11T14:11:53.786797Z",
     "shell.execute_reply": "2020-12-11T14:11:53.786283Z"
    },
    "papermill": {
     "duration": 0.035044,
     "end_time": "2020-12-11T14:11:53.786900",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.751856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_log_loss(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for i, target in enumerate(targets):\n",
    "        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.846556Z",
     "iopub.status.busy": "2020-12-11T14:11:53.845815Z",
     "iopub.status.idle": "2020-12-11T14:11:53.849083Z",
     "shell.execute_reply": "2020-12-11T14:11:53.849509Z"
    },
    "papermill": {
     "duration": 0.037596,
     "end_time": "2020-12-11T14:11:53.849632",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.812036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogitsLogLoss(Metric):\n",
    "    \"\"\"\n",
    "    LogLoss with sigmoid applied\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._name = \"logits_ll\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Compute LogLoss of predictions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true: np.ndarray\n",
    "            Target matrix or vector\n",
    "        y_score: np.ndarray\n",
    "            Score matrix or vector\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            float\n",
    "            LogLoss of predictions vs targets.\n",
    "        \"\"\"\n",
    "        logits = 1 / (1 + np.exp(-y_pred))\n",
    "        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n",
    "        return np.mean(-aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.904788Z",
     "iopub.status.busy": "2020-12-11T14:11:53.904151Z",
     "iopub.status.idle": "2020-12-11T14:11:53.909845Z",
     "shell.execute_reply": "2020-12-11T14:11:53.910438Z"
    },
    "papermill": {
     "duration": 0.036299,
     "end_time": "2020-12-11T14:11:53.910566",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.874267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00142804, 0.00172544, 0.00309356, ..., 0.00229157, 0.00430772,\n",
       "        0.00202517],\n",
       "       [0.00099383, 0.00179054, 0.00308135, ..., 0.00225782, 0.00113765,\n",
       "        0.00293713],\n",
       "       [0.00137616, 0.00148251, 0.0024345 , ..., 0.0022994 , 0.00094954,\n",
       "        0.00226204],\n",
       "       ...,\n",
       "       [0.00188603, 0.00172753, 0.00144775, ..., 0.0019423 , 0.00076604,\n",
       "        0.00144087],\n",
       "       [0.00223348, 0.00146616, 0.00178669, ..., 0.00260949, 0.00093238,\n",
       "        0.00307839],\n",
       "       [0.00124144, 0.00157797, 0.00167693, ..., 0.00229663, 0.00066319,\n",
       "        0.00171414]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-12-11T14:11:53.988164Z",
     "iopub.status.busy": "2020-12-11T14:11:53.987275Z",
     "iopub.status.idle": "2020-12-11T15:24:24.423070Z",
     "shell.execute_reply": "2020-12-11T15:24:24.422472Z"
    },
    "papermill": {
     "duration": 4350.485179,
     "end_time": "2020-12-11T15:24:24.423185",
     "exception": false,
     "start_time": "2020-12-11T14:11:53.938006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seed 0\n",
      "Train fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31312 | val_logits_ll: 0.02732 |  0:00:02s\n",
      "epoch 10 | loss: 0.02267 | val_logits_ll: 0.0193  |  0:00:19s\n",
      "epoch 20 | loss: 0.02128 | val_logits_ll: 0.01847 |  0:00:36s\n",
      "epoch 30 | loss: 0.02095 | val_logits_ll: 0.01792 |  0:00:55s\n",
      "epoch 40 | loss: 0.02079 | val_logits_ll: 0.0177  |  0:01:12s\n",
      "epoch 50 | loss: 0.02056 | val_logits_ll: 0.01758 |  0:01:29s\n",
      "epoch 60 | loss: 0.02034 | val_logits_ll: 0.0176  |  0:01:46s\n",
      "epoch 70 | loss: 0.02019 | val_logits_ll: 0.01769 |  0:02:05s\n",
      "epoch 80 | loss: 0.01999 | val_logits_ll: 0.01773 |  0:02:22s\n",
      "epoch 90 | loss: 0.01987 | val_logits_ll: 0.01746 |  0:02:39s\n",
      "epoch 100| loss: 0.01964 | val_logits_ll: 0.01758 |  0:02:58s\n",
      "epoch 110| loss: 0.01942 | val_logits_ll: 0.01752 |  0:03:15s\n",
      "\n",
      "Early stopping occured at epoch 114 with best_epoch = 84 and best_val_logits_ll = 0.01732\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold0_seed0.zip\n",
      "Weights saved!\n",
      "Train fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31809 | val_logits_ll: 0.02632 |  0:00:01s\n",
      "epoch 10 | loss: 0.02262 | val_logits_ll: 0.01856 |  0:00:19s\n",
      "epoch 20 | loss: 0.02135 | val_logits_ll: 0.018   |  0:00:38s\n",
      "epoch 30 | loss: 0.02101 | val_logits_ll: 0.0183  |  0:00:55s\n",
      "epoch 40 | loss: 0.02075 | val_logits_ll: 0.01743 |  0:01:12s\n",
      "epoch 50 | loss: 0.02064 | val_logits_ll: 0.01744 |  0:01:29s\n",
      "epoch 60 | loss: 0.02054 | val_logits_ll: 0.01728 |  0:01:47s\n",
      "epoch 70 | loss: 0.02031 | val_logits_ll: 0.01731 |  0:02:04s\n",
      "epoch 80 | loss: 0.02023 | val_logits_ll: 0.01722 |  0:02:21s\n",
      "epoch 90 | loss: 0.02005 | val_logits_ll: 0.01721 |  0:02:39s\n",
      "epoch 100| loss: 0.02003 | val_logits_ll: 0.01731 |  0:02:57s\n",
      "epoch 110| loss: 0.01975 | val_logits_ll: 0.01731 |  0:03:14s\n",
      "\n",
      "Early stopping occured at epoch 118 with best_epoch = 88 and best_val_logits_ll = 0.01709\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold1_seed0.zip\n",
      "Weights saved!\n",
      "Train fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3166  | val_logits_ll: 0.02744 |  0:00:01s\n",
      "epoch 10 | loss: 0.0226  | val_logits_ll: 0.02132 |  0:00:19s\n",
      "epoch 20 | loss: 0.02131 | val_logits_ll: 0.01909 |  0:00:36s\n",
      "epoch 30 | loss: 0.02082 | val_logits_ll: 0.01824 |  0:00:54s\n",
      "epoch 40 | loss: 0.02058 | val_logits_ll: 0.01823 |  0:01:12s\n",
      "epoch 50 | loss: 0.02039 | val_logits_ll: 0.01816 |  0:01:30s\n",
      "epoch 60 | loss: 0.02024 | val_logits_ll: 0.01798 |  0:01:47s\n",
      "epoch 70 | loss: 0.02011 | val_logits_ll: 0.01821 |  0:02:05s\n",
      "epoch 80 | loss: 0.01992 | val_logits_ll: 0.01802 |  0:02:23s\n",
      "epoch 90 | loss: 0.02063 | val_logits_ll: 0.01812 |  0:02:40s\n",
      "epoch 100| loss: 0.02013 | val_logits_ll: 0.01801 |  0:02:59s\n",
      "\n",
      "Early stopping occured at epoch 103 with best_epoch = 73 and best_val_logits_ll = 0.01792\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold2_seed0.zip\n",
      "Weights saved!\n",
      "Train fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31421 | val_logits_ll: 0.02776 |  0:00:01s\n",
      "epoch 10 | loss: 0.02271 | val_logits_ll: 0.01884 |  0:00:19s\n",
      "epoch 20 | loss: 0.02144 | val_logits_ll: 0.01813 |  0:00:37s\n",
      "epoch 30 | loss: 0.02112 | val_logits_ll: 0.01765 |  0:00:55s\n",
      "epoch 40 | loss: 0.02092 | val_logits_ll: 0.01746 |  0:01:13s\n",
      "epoch 50 | loss: 0.0207  | val_logits_ll: 0.01761 |  0:01:31s\n",
      "epoch 60 | loss: 0.02061 | val_logits_ll: 0.01723 |  0:01:48s\n",
      "epoch 70 | loss: 0.02045 | val_logits_ll: 0.01716 |  0:02:07s\n",
      "epoch 80 | loss: 0.02034 | val_logits_ll: 0.0172  |  0:02:25s\n",
      "epoch 90 | loss: 0.02017 | val_logits_ll: 0.01732 |  0:02:43s\n",
      "epoch 100| loss: 0.02003 | val_logits_ll: 0.01696 |  0:03:02s\n",
      "epoch 110| loss: 0.01992 | val_logits_ll: 0.01695 |  0:03:20s\n",
      "epoch 120| loss: 0.01978 | val_logits_ll: 0.01706 |  0:03:38s\n",
      "epoch 130| loss: 0.01959 | val_logits_ll: 0.01702 |  0:03:57s\n",
      "epoch 140| loss: 0.01942 | val_logits_ll: 0.0171  |  0:04:15s\n",
      "epoch 150| loss: 0.01922 | val_logits_ll: 0.0171  |  0:04:33s\n",
      "\n",
      "Early stopping occured at epoch 151 with best_epoch = 121 and best_val_logits_ll = 0.01683\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold3_seed0.zip\n",
      "Weights saved!\n",
      "Train fold 5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31773 | val_logits_ll: 0.02803 |  0:00:01s\n",
      "epoch 10 | loss: 0.02267 | val_logits_ll: 0.01931 |  0:00:21s\n",
      "epoch 20 | loss: 0.02132 | val_logits_ll: 0.01844 |  0:00:38s\n",
      "epoch 30 | loss: 0.02098 | val_logits_ll: 0.01824 |  0:00:56s\n",
      "epoch 40 | loss: 0.02084 | val_logits_ll: 0.01787 |  0:01:14s\n",
      "epoch 50 | loss: 0.02072 | val_logits_ll: 0.01792 |  0:01:32s\n",
      "epoch 60 | loss: 0.02047 | val_logits_ll: 0.0178  |  0:01:50s\n",
      "epoch 70 | loss: 0.02028 | val_logits_ll: 0.0177  |  0:02:07s\n",
      "epoch 80 | loss: 0.02005 | val_logits_ll: 0.01773 |  0:02:26s\n",
      "epoch 90 | loss: 0.01997 | val_logits_ll: 0.01746 |  0:02:43s\n",
      "epoch 100| loss: 0.01986 | val_logits_ll: 0.01782 |  0:03:01s\n",
      "epoch 110| loss: 0.0196  | val_logits_ll: 0.01757 |  0:03:20s\n",
      "epoch 120| loss: 0.01952 | val_logits_ll: 0.01776 |  0:03:37s\n",
      "\n",
      "Early stopping occured at epoch 120 with best_epoch = 90 and best_val_logits_ll = 0.01746\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold4_seed0.zip\n",
      "Weights saved!\n",
      "Train fold 6\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31435 | val_logits_ll: 0.02797 |  0:00:01s\n",
      "epoch 10 | loss: 0.02265 | val_logits_ll: 0.01931 |  0:00:19s\n",
      "epoch 20 | loss: 0.02136 | val_logits_ll: 0.01874 |  0:00:37s\n",
      "epoch 30 | loss: 0.02098 | val_logits_ll: 0.01809 |  0:00:55s\n",
      "epoch 40 | loss: 0.0208  | val_logits_ll: 0.01802 |  0:01:12s\n",
      "epoch 50 | loss: 0.02057 | val_logits_ll: 0.01807 |  0:01:30s\n",
      "epoch 60 | loss: 0.02044 | val_logits_ll: 0.01773 |  0:01:48s\n",
      "epoch 70 | loss: 0.02033 | val_logits_ll: 0.01802 |  0:02:05s\n",
      "epoch 80 | loss: 0.02022 | val_logits_ll: 0.01806 |  0:02:23s\n",
      "epoch 90 | loss: 0.02011 | val_logits_ll: 0.01791 |  0:02:41s\n",
      "epoch 100| loss: 0.02001 | val_logits_ll: 0.01787 |  0:02:59s\n",
      "epoch 110| loss: 0.01977 | val_logits_ll: 0.01774 |  0:03:16s\n",
      "epoch 120| loss: 0.01962 | val_logits_ll: 0.01789 |  0:03:34s\n",
      "epoch 130| loss: 0.01949 | val_logits_ll: 0.01781 |  0:03:52s\n",
      "epoch 140| loss: 0.0193  | val_logits_ll: 0.018   |  0:04:09s\n",
      "\n",
      "Early stopping occured at epoch 141 with best_epoch = 111 and best_val_logits_ll = 0.01769\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold5_seed0.zip\n",
      "Weights saved!\n",
      "Train fold 7\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.31443 | val_logits_ll: 0.02741 |  0:00:01s\n",
      "epoch 10 | loss: 0.02276 | val_logits_ll: 0.02085 |  0:00:18s\n",
      "epoch 20 | loss: 0.02138 | val_logits_ll: 0.01758 |  0:00:37s\n",
      "epoch 30 | loss: 0.02099 | val_logits_ll: 0.01731 |  0:00:55s\n",
      "epoch 40 | loss: 0.02077 | val_logits_ll: 0.01713 |  0:01:12s\n",
      "epoch 50 | loss: 0.02063 | val_logits_ll: 0.01705 |  0:01:30s\n",
      "epoch 60 | loss: 0.0205  | val_logits_ll: 0.01728 |  0:01:47s\n",
      "epoch 70 | loss: 0.02022 | val_logits_ll: 0.01701 |  0:02:05s\n",
      "epoch 80 | loss: 0.02013 | val_logits_ll: 0.01702 |  0:02:23s\n",
      "epoch 90 | loss: 0.01992 | val_logits_ll: 0.01694 |  0:02:40s\n",
      "epoch 100| loss: 0.01991 | val_logits_ll: 0.01693 |  0:02:57s\n",
      "epoch 110| loss: 0.01961 | val_logits_ll: 0.017   |  0:03:14s\n",
      "epoch 120| loss: 0.01942 | val_logits_ll: 0.01711 |  0:03:33s\n",
      "\n",
      "Early stopping occured at epoch 124 with best_epoch = 94 and best_val_logits_ll = 0.01677\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold6_seed0.zip\n",
      "Weights saved!\n",
      "Score for this seed 0.01729\n",
      "Train seed 1\n",
      "Train fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29917 | val_logits_ll: 0.02731 |  0:00:01s\n",
      "epoch 10 | loss: 0.02238 | val_logits_ll: 0.0191  |  0:00:18s\n",
      "epoch 20 | loss: 0.02135 | val_logits_ll: 0.02127 |  0:00:35s\n",
      "epoch 30 | loss: 0.02091 | val_logits_ll: 0.0179  |  0:00:53s\n",
      "epoch 40 | loss: 0.02081 | val_logits_ll: 0.01789 |  0:01:11s\n",
      "epoch 50 | loss: 0.02057 | val_logits_ll: 0.01764 |  0:01:28s\n",
      "epoch 60 | loss: 0.02041 | val_logits_ll: 0.01745 |  0:01:45s\n",
      "epoch 70 | loss: 0.02026 | val_logits_ll: 0.01761 |  0:02:03s\n",
      "epoch 80 | loss: 0.01999 | val_logits_ll: 0.01742 |  0:02:20s\n",
      "epoch 90 | loss: 0.01981 | val_logits_ll: 0.01743 |  0:02:37s\n",
      "epoch 100| loss: 0.01965 | val_logits_ll: 0.01749 |  0:02:55s\n",
      "epoch 110| loss: 0.01955 | val_logits_ll: 0.01765 |  0:03:12s\n",
      "epoch 120| loss: 0.01919 | val_logits_ll: 0.01765 |  0:03:29s\n",
      "epoch 130| loss: 0.01898 | val_logits_ll: 0.01763 |  0:03:48s\n",
      "\n",
      "Early stopping occured at epoch 131 with best_epoch = 101 and best_val_logits_ll = 0.01735\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold0_seed1.zip\n",
      "Weights saved!\n",
      "Train fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30115 | val_logits_ll: 0.02709 |  0:00:01s\n",
      "epoch 10 | loss: 0.02246 | val_logits_ll: 0.0186  |  0:00:19s\n",
      "epoch 20 | loss: 0.02131 | val_logits_ll: 0.01813 |  0:00:35s\n",
      "epoch 30 | loss: 0.02104 | val_logits_ll: 0.01804 |  0:00:53s\n",
      "epoch 40 | loss: 0.02075 | val_logits_ll: 0.01746 |  0:01:10s\n",
      "epoch 50 | loss: 0.02037 | val_logits_ll: 0.01742 |  0:01:27s\n",
      "epoch 60 | loss: 0.02022 | val_logits_ll: 0.01728 |  0:01:44s\n",
      "epoch 70 | loss: 0.01996 | val_logits_ll: 0.01728 |  0:02:03s\n",
      "epoch 80 | loss: 0.01983 | val_logits_ll: 0.01756 |  0:02:20s\n",
      "epoch 90 | loss: 0.01963 | val_logits_ll: 0.01732 |  0:02:37s\n",
      "epoch 100| loss: 0.01948 | val_logits_ll: 0.01742 |  0:02:55s\n",
      "epoch 110| loss: 0.01916 | val_logits_ll: 0.01736 |  0:03:12s\n",
      "epoch 120| loss: 0.01899 | val_logits_ll: 0.01755 |  0:03:29s\n",
      "\n",
      "Early stopping occured at epoch 121 with best_epoch = 91 and best_val_logits_ll = 0.01712\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold1_seed1.zip\n",
      "Weights saved!\n",
      "Train fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29836 | val_logits_ll: 0.02885 |  0:00:01s\n",
      "epoch 10 | loss: 0.02261 | val_logits_ll: 0.01991 |  0:00:20s\n",
      "epoch 20 | loss: 0.02167 | val_logits_ll: 0.02009 |  0:00:37s\n",
      "epoch 30 | loss: 0.02096 | val_logits_ll: 0.01811 |  0:00:54s\n",
      "epoch 40 | loss: 0.02062 | val_logits_ll: 0.01848 |  0:01:12s\n",
      "epoch 50 | loss: 0.02045 | val_logits_ll: 0.01814 |  0:01:29s\n",
      "epoch 60 | loss: 0.02024 | val_logits_ll: 0.01808 |  0:01:46s\n",
      "epoch 70 | loss: 0.02005 | val_logits_ll: 0.01818 |  0:02:03s\n",
      "epoch 80 | loss: 0.01978 | val_logits_ll: 0.01825 |  0:02:21s\n",
      "epoch 90 | loss: 0.01958 | val_logits_ll: 0.01814 |  0:02:38s\n",
      "\n",
      "Early stopping occured at epoch 91 with best_epoch = 61 and best_val_logits_ll = 0.01794\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold2_seed1.zip\n",
      "Weights saved!\n",
      "Train fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29974 | val_logits_ll: 0.02667 |  0:00:02s\n",
      "epoch 10 | loss: 0.02271 | val_logits_ll: 0.01897 |  0:00:18s\n",
      "epoch 20 | loss: 0.02146 | val_logits_ll: 0.01962 |  0:00:36s\n",
      "epoch 30 | loss: 0.02102 | val_logits_ll: 0.01751 |  0:00:53s\n",
      "epoch 40 | loss: 0.02077 | val_logits_ll: 0.01782 |  0:01:11s\n",
      "epoch 50 | loss: 0.0206  | val_logits_ll: 0.01725 |  0:01:28s\n",
      "epoch 60 | loss: 0.02041 | val_logits_ll: 0.01719 |  0:01:46s\n",
      "epoch 70 | loss: 0.02029 | val_logits_ll: 0.01707 |  0:02:03s\n",
      "epoch 80 | loss: 0.02015 | val_logits_ll: 0.01713 |  0:02:20s\n",
      "epoch 90 | loss: 0.02004 | val_logits_ll: 0.01725 |  0:02:38s\n",
      "epoch 100| loss: 0.01988 | val_logits_ll: 0.01707 |  0:02:55s\n",
      "epoch 110| loss: 0.01983 | val_logits_ll: 0.01701 |  0:03:12s\n",
      "epoch 120| loss: 0.01972 | val_logits_ll: 0.01699 |  0:03:29s\n",
      "epoch 130| loss: 0.01961 | val_logits_ll: 0.01715 |  0:03:48s\n",
      "epoch 140| loss: 0.01936 | val_logits_ll: 0.01712 |  0:04:05s\n",
      "\n",
      "Early stopping occured at epoch 143 with best_epoch = 113 and best_val_logits_ll = 0.01687\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold3_seed1.zip\n",
      "Weights saved!\n",
      "Train fold 5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.30209 | val_logits_ll: 0.02827 |  0:00:01s\n",
      "epoch 10 | loss: 0.0225  | val_logits_ll: 0.01945 |  0:00:18s\n",
      "epoch 20 | loss: 0.02127 | val_logits_ll: 0.0185  |  0:00:36s\n",
      "epoch 30 | loss: 0.02101 | val_logits_ll: 0.0184  |  0:00:54s\n",
      "epoch 40 | loss: 0.0206  | val_logits_ll: 0.01783 |  0:01:11s\n",
      "epoch 50 | loss: 0.02043 | val_logits_ll: 0.01777 |  0:01:29s\n",
      "epoch 60 | loss: 0.02022 | val_logits_ll: 0.01773 |  0:01:47s\n",
      "epoch 70 | loss: 0.02007 | val_logits_ll: 0.0176  |  0:02:04s\n",
      "epoch 80 | loss: 0.01983 | val_logits_ll: 0.01767 |  0:02:22s\n",
      "epoch 90 | loss: 0.01964 | val_logits_ll: 0.01753 |  0:02:39s\n",
      "epoch 100| loss: 0.01952 | val_logits_ll: 0.01751 |  0:02:56s\n",
      "epoch 110| loss: 0.01927 | val_logits_ll: 0.01761 |  0:03:13s\n",
      "\n",
      "Early stopping occured at epoch 112 with best_epoch = 82 and best_val_logits_ll = 0.01751\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold4_seed1.zip\n",
      "Weights saved!\n",
      "Train fold 6\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.3013  | val_logits_ll: 0.02789 |  0:00:01s\n",
      "epoch 10 | loss: 0.02252 | val_logits_ll: 0.02163 |  0:00:19s\n",
      "epoch 20 | loss: 0.02141 | val_logits_ll: 0.01844 |  0:00:37s\n",
      "epoch 30 | loss: 0.02097 | val_logits_ll: 0.01814 |  0:00:53s\n",
      "epoch 40 | loss: 0.02069 | val_logits_ll: 0.01804 |  0:01:13s\n",
      "epoch 50 | loss: 0.02046 | val_logits_ll: 0.01789 |  0:01:30s\n",
      "epoch 60 | loss: 0.02039 | val_logits_ll: 0.01777 |  0:01:48s\n",
      "epoch 70 | loss: 0.02012 | val_logits_ll: 0.01788 |  0:02:06s\n",
      "epoch 80 | loss: 0.02001 | val_logits_ll: 0.01785 |  0:02:24s\n",
      "\n",
      "Early stopping occured at epoch 86 with best_epoch = 56 and best_val_logits_ll = 0.01768\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold5_seed1.zip\n",
      "Weights saved!\n",
      "Train fold 7\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29924 | val_logits_ll: 0.02829 |  0:00:02s\n",
      "epoch 10 | loss: 0.02242 | val_logits_ll: 0.01944 |  0:00:19s\n",
      "epoch 20 | loss: 0.02151 | val_logits_ll: 0.0187  |  0:00:38s\n",
      "epoch 30 | loss: 0.02116 | val_logits_ll: 0.01749 |  0:00:55s\n",
      "epoch 40 | loss: 0.0209  | val_logits_ll: 0.01789 |  0:01:13s\n",
      "epoch 50 | loss: 0.02066 | val_logits_ll: 0.01712 |  0:01:30s\n",
      "epoch 60 | loss: 0.0204  | val_logits_ll: 0.01726 |  0:01:48s\n",
      "epoch 70 | loss: 0.02025 | val_logits_ll: 0.01712 |  0:02:05s\n",
      "epoch 80 | loss: 0.01995 | val_logits_ll: 0.01711 |  0:02:23s\n",
      "epoch 90 | loss: 0.01984 | val_logits_ll: 0.0171  |  0:02:41s\n",
      "epoch 100| loss: 0.01966 | val_logits_ll: 0.01702 |  0:02:58s\n",
      "epoch 110| loss: 0.01941 | val_logits_ll: 0.01714 |  0:03:16s\n",
      "\n",
      "Early stopping occured at epoch 118 with best_epoch = 88 and best_val_logits_ll = 0.01675\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold6_seed1.zip\n",
      "Weights saved!\n",
      "Score for this seed 0.01732\n",
      "Train seed 2\n",
      "Train fold 1\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28923 | val_logits_ll: 0.02722 |  0:00:01s\n",
      "epoch 10 | loss: 0.02221 | val_logits_ll: 0.01884 |  0:00:19s\n",
      "epoch 20 | loss: 0.0212  | val_logits_ll: 0.01813 |  0:00:37s\n",
      "epoch 30 | loss: 0.02086 | val_logits_ll: 0.01765 |  0:00:55s\n",
      "epoch 40 | loss: 0.02061 | val_logits_ll: 0.01752 |  0:01:12s\n",
      "epoch 50 | loss: 0.02053 | val_logits_ll: 0.01755 |  0:01:30s\n",
      "epoch 60 | loss: 0.02027 | val_logits_ll: 0.01752 |  0:01:47s\n",
      "epoch 70 | loss: 0.02    | val_logits_ll: 0.01744 |  0:02:06s\n",
      "epoch 80 | loss: 0.01978 | val_logits_ll: 0.0174  |  0:02:23s\n",
      "\n",
      "Early stopping occured at epoch 81 with best_epoch = 51 and best_val_logits_ll = 0.01725\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold0_seed2.zip\n",
      "Weights saved!\n",
      "Train fold 2\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29266 | val_logits_ll: 0.02656 |  0:00:01s\n",
      "epoch 10 | loss: 0.02291 | val_logits_ll: 0.01881 |  0:00:18s\n",
      "epoch 20 | loss: 0.02129 | val_logits_ll: 0.01838 |  0:00:37s\n",
      "epoch 30 | loss: 0.02099 | val_logits_ll: 0.01778 |  0:00:54s\n",
      "epoch 40 | loss: 0.02075 | val_logits_ll: 0.01755 |  0:01:11s\n",
      "epoch 50 | loss: 0.02058 | val_logits_ll: 0.01746 |  0:01:29s\n",
      "epoch 60 | loss: 0.02039 | val_logits_ll: 0.01744 |  0:01:46s\n",
      "epoch 70 | loss: 0.02029 | val_logits_ll: 0.0172  |  0:02:04s\n",
      "epoch 80 | loss: 0.0201  | val_logits_ll: 0.01748 |  0:02:21s\n",
      "epoch 90 | loss: 0.01997 | val_logits_ll: 0.0173  |  0:02:40s\n",
      "epoch 100| loss: 0.0198  | val_logits_ll: 0.01737 |  0:02:57s\n",
      "epoch 110| loss: 0.01963 | val_logits_ll: 0.01728 |  0:03:15s\n",
      "epoch 120| loss: 0.01955 | val_logits_ll: 0.0172  |  0:03:33s\n",
      "\n",
      "Early stopping occured at epoch 127 with best_epoch = 97 and best_val_logits_ll = 0.01714\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold1_seed2.zip\n",
      "Weights saved!\n",
      "Train fold 3\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29378 | val_logits_ll: 0.02833 |  0:00:01s\n",
      "epoch 10 | loss: 0.02246 | val_logits_ll: 0.01946 |  0:00:18s\n",
      "epoch 20 | loss: 0.02119 | val_logits_ll: 0.01854 |  0:00:36s\n",
      "epoch 30 | loss: 0.02076 | val_logits_ll: 0.01823 |  0:00:54s\n",
      "epoch 40 | loss: 0.02055 | val_logits_ll: 0.01838 |  0:01:11s\n",
      "epoch 50 | loss: 0.02048 | val_logits_ll: 0.01805 |  0:01:29s\n",
      "epoch 60 | loss: 0.02018 | val_logits_ll: 0.01802 |  0:01:47s\n",
      "epoch 70 | loss: 0.02013 | val_logits_ll: 0.01793 |  0:02:04s\n",
      "epoch 80 | loss: 0.02004 | val_logits_ll: 0.01794 |  0:02:22s\n",
      "epoch 90 | loss: 0.01982 | val_logits_ll: 0.01808 |  0:02:40s\n",
      "epoch 100| loss: 0.01962 | val_logits_ll: 0.01804 |  0:02:58s\n",
      "\n",
      "Early stopping occured at epoch 107 with best_epoch = 77 and best_val_logits_ll = 0.0178\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold2_seed2.zip\n",
      "Weights saved!\n",
      "Train fold 4\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29381 | val_logits_ll: 0.02721 |  0:00:01s\n",
      "epoch 10 | loss: 0.02255 | val_logits_ll: 0.01843 |  0:00:18s\n",
      "epoch 20 | loss: 0.02141 | val_logits_ll: 0.02247 |  0:00:36s\n",
      "epoch 30 | loss: 0.02096 | val_logits_ll: 0.01765 |  0:00:54s\n",
      "epoch 40 | loss: 0.0206  | val_logits_ll: 0.01741 |  0:01:11s\n",
      "epoch 50 | loss: 0.02047 | val_logits_ll: 0.01725 |  0:01:30s\n",
      "epoch 60 | loss: 0.02077 | val_logits_ll: 0.01719 |  0:01:47s\n",
      "epoch 70 | loss: 0.02019 | val_logits_ll: 0.0171  |  0:02:05s\n",
      "epoch 80 | loss: 0.01991 | val_logits_ll: 0.01703 |  0:02:22s\n",
      "epoch 90 | loss: 0.01973 | val_logits_ll: 0.01698 |  0:02:40s\n",
      "\n",
      "Early stopping occured at epoch 95 with best_epoch = 65 and best_val_logits_ll = 0.01688\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold3_seed2.zip\n",
      "Weights saved!\n",
      "Train fold 5\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.28915 | val_logits_ll: 0.02748 |  0:00:01s\n",
      "epoch 10 | loss: 0.02269 | val_logits_ll: 0.01955 |  0:00:19s\n",
      "epoch 20 | loss: 0.02129 | val_logits_ll: 0.01889 |  0:00:36s\n",
      "epoch 30 | loss: 0.021   | val_logits_ll: 0.01839 |  0:00:55s\n",
      "epoch 40 | loss: 0.02068 | val_logits_ll: 0.01778 |  0:01:13s\n",
      "epoch 50 | loss: 0.02058 | val_logits_ll: 0.01787 |  0:01:31s\n",
      "epoch 60 | loss: 0.02037 | val_logits_ll: 0.01775 |  0:01:50s\n",
      "epoch 70 | loss: 0.02029 | val_logits_ll: 0.01774 |  0:02:07s\n",
      "epoch 80 | loss: 0.02014 | val_logits_ll: 0.01773 |  0:02:24s\n",
      "epoch 90 | loss: 0.02003 | val_logits_ll: 0.01771 |  0:02:42s\n",
      "epoch 100| loss: 0.01986 | val_logits_ll: 0.01766 |  0:03:00s\n",
      "epoch 110| loss: 0.01973 | val_logits_ll: 0.01766 |  0:03:18s\n",
      "epoch 120| loss: 0.01959 | val_logits_ll: 0.01773 |  0:03:36s\n",
      "\n",
      "Early stopping occured at epoch 121 with best_epoch = 91 and best_val_logits_ll = 0.01748\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold4_seed2.zip\n",
      "Weights saved!\n",
      "Train fold 6\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29163 | val_logits_ll: 0.02853 |  0:00:02s\n",
      "epoch 10 | loss: 0.02259 | val_logits_ll: 0.01924 |  0:00:20s\n",
      "epoch 20 | loss: 0.0213  | val_logits_ll: 0.01848 |  0:00:37s\n",
      "epoch 30 | loss: 0.02095 | val_logits_ll: 0.01798 |  0:00:55s\n",
      "epoch 40 | loss: 0.02071 | val_logits_ll: 0.01807 |  0:01:13s\n",
      "epoch 50 | loss: 0.02055 | val_logits_ll: 0.01793 |  0:01:31s\n",
      "epoch 60 | loss: 0.02028 | val_logits_ll: 0.01792 |  0:01:48s\n",
      "epoch 70 | loss: 0.02021 | val_logits_ll: 0.01785 |  0:02:07s\n",
      "epoch 80 | loss: 0.0201  | val_logits_ll: 0.01786 |  0:02:24s\n",
      "epoch 90 | loss: 0.01986 | val_logits_ll: 0.01802 |  0:02:41s\n",
      "\n",
      "Early stopping occured at epoch 99 with best_epoch = 69 and best_val_logits_ll = 0.01766\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold5_seed2.zip\n",
      "Weights saved!\n",
      "Train fold 7\n",
      "Device used : cuda\n",
      "epoch 0  | loss: 0.29231 | val_logits_ll: 0.02686 |  0:00:02s\n",
      "epoch 10 | loss: 0.02261 | val_logits_ll: 0.01864 |  0:00:19s\n",
      "epoch 20 | loss: 0.02127 | val_logits_ll: 0.01894 |  0:00:37s\n",
      "epoch 30 | loss: 0.02102 | val_logits_ll: 0.01744 |  0:00:53s\n",
      "epoch 40 | loss: 0.02063 | val_logits_ll: 0.01716 |  0:01:12s\n",
      "epoch 50 | loss: 0.0204  | val_logits_ll: 0.01703 |  0:01:29s\n",
      "epoch 60 | loss: 0.02029 | val_logits_ll: 0.01686 |  0:01:47s\n",
      "epoch 70 | loss: 0.02006 | val_logits_ll: 0.01708 |  0:02:06s\n",
      "epoch 80 | loss: 0.01998 | val_logits_ll: 0.01686 |  0:02:23s\n",
      "epoch 90 | loss: 0.01973 | val_logits_ll: 0.01678 |  0:02:40s\n",
      "epoch 100| loss: 0.01957 | val_logits_ll: 0.01694 |  0:02:57s\n",
      "epoch 110| loss: 0.01923 | val_logits_ll: 0.01694 |  0:03:16s\n",
      "epoch 120| loss: 0.01916 | val_logits_ll: 0.01694 |  0:03:33s\n",
      "\n",
      "Early stopping occured at epoch 120 with best_epoch = 90 and best_val_logits_ll = 0.01678\n",
      "Best weights from best epoch are automatically used!\n",
      "Saving weights...\n",
      "Successfully saved model at tabnet fold6_seed2.zip\n",
      "Weights saved!\n",
      "Score for this seed 0.01728\n",
      "Overall score is 0.01698\n"
     ]
    }
   ],
   "source": [
    "for seed in range(nstarts):\n",
    "    print(f'Train seed {seed}')\n",
    "    set_seed(seed)\n",
    "    seed_oof = []\n",
    "    seed_targets = []\n",
    "    seed_preds = np.zeros((len(test), ntargets, nfolds))\n",
    "    \n",
    "    for n in range(nfolds):\n",
    "        print(f'Train fold {n+1}')\n",
    "        xtrain, xval = train[folds!=n], train[folds==n]\n",
    "        ytrain, yval = train_targets[folds!=n], train_targets[folds==n]\n",
    "        xtrain = np.concatenate([xtrain, train_pl], axis=0)\n",
    "        ytrain = np.concatenate([ytrain, train_targets_pl], axis=0)\n",
    "        \n",
    "        tabnet_params = dict(\n",
    "              n_d = 32,\n",
    "              n_a = 32,\n",
    "              n_steps = 1,\n",
    "              gamma = 1.3,\n",
    "              lambda_sparse = 0,\n",
    "              optimizer_fn = optim.Adam,\n",
    "              optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n",
    "              mask_type = \"entmax\",\n",
    "              scheduler_params = dict(mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n",
    "              scheduler_fn = ReduceLROnPlateau,\n",
    "              #seed = 42,\n",
    "              verbose = 10\n",
    "                     )\n",
    "        model = TabNetRegressor(**tabnet_params, seed=seed)\n",
    "        model.fit(\n",
    "            X_train = xtrain,\n",
    "            y_train = ytrain,\n",
    "            eval_set = [(xval, yval)],\n",
    "            eval_name = [\"val\"],\n",
    "            eval_metric = [\"logits_ll\"],\n",
    "            max_epochs = nepochs,\n",
    "            patience = 30,\n",
    "            batch_size = 1024,\n",
    "            virtual_batch_size = 32,\n",
    "            num_workers = 1,\n",
    "            drop_last = False,\n",
    "            loss_fn = trn_criterion\n",
    "        )\n",
    "        #######################\n",
    "        #### SAVE WEIGHTS #####\n",
    "        #######################\n",
    "        print('Saving weights...')\n",
    "        path = f\"tabnet fold{n}_seed{seed}\"\n",
    "        model.save_model(path)\n",
    "        print('Weights saved!')\n",
    "        \n",
    "        ##################\n",
    "        ### INFERENCE ####\n",
    "        ##################\n",
    "        #print('Loading weights...')\n",
    "        #model.load_model(path)\n",
    "        fold_oof = model.predict(xval)\n",
    "        fold_oof = 1 / (1 + np.exp(-fold_oof))\n",
    "        fold_preds = model.predict(test)\n",
    "        fold_preds = 1 / (1 + np.exp(-fold_preds))\n",
    "        \n",
    "        seed_oof.append(fold_oof)\n",
    "        seed_targets.append(yval)\n",
    "        seed_preds[:, :, n] = fold_preds\n",
    "    \n",
    "    seed_oof = np.concatenate(seed_oof)\n",
    "    seed_targets = np.concatenate(seed_targets)\n",
    "    seed_preds = np.mean(seed_preds, axis=2)\n",
    "    \n",
    "    print(\"Score for this seed {:5.5f}\".format(mean_log_loss(seed_targets, seed_oof)))\n",
    "    oof_targets = seed_targets\n",
    "    oof[:, seed, :] = seed_oof\n",
    "    preds += seed_preds / nstarts\n",
    "\n",
    "oof = np.mean(oof, axis=1)\n",
    "print(\"Overall score is {:5.5f}\".format(mean_log_loss(oof_targets, oof)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:24:24.702171Z",
     "iopub.status.busy": "2020-12-11T15:24:24.701076Z",
     "iopub.status.idle": "2020-12-11T15:24:25.479215Z",
     "shell.execute_reply": "2020-12-11T15:24:25.479724Z"
    },
    "papermill": {
     "duration": 0.919341,
     "end_time": "2020-12-11T15:24:25.479901",
     "exception": false,
     "start_time": "2020-12-11T15:24:24.560560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall score is 0.01698\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall score is {:5.5f}\".format(mean_log_loss(oof_targets, oof)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:24:25.752573Z",
     "iopub.status.busy": "2020-12-11T15:24:25.751591Z",
     "iopub.status.idle": "2020-12-11T15:24:25.804856Z",
     "shell.execute_reply": "2020-12-11T15:24:25.804314Z"
    },
    "papermill": {
     "duration": 0.192086,
     "end_time": "2020-12-11T15:24:25.804977",
     "exception": false,
     "start_time": "2020-12-11T15:24:25.612891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('tabnet_oof.npy', oof)\n",
    "np.save('tabnet_targets.npy', oof_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:24:26.079023Z",
     "iopub.status.busy": "2020-12-11T15:24:26.078065Z",
     "iopub.status.idle": "2020-12-11T15:24:28.728296Z",
     "shell.execute_reply": "2020-12-11T15:24:28.728833Z"
    },
    "papermill": {
     "duration": 2.791644,
     "end_time": "2020-12-11T15:24:28.729039",
     "exception": false,
     "start_time": "2020-12-11T15:24:25.937395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss[targets] = preds\n",
    "ss.loc[test_features['cp_type']=='ctl_vehicle', targets] = 0\n",
    "ss.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 4444.410716,
   "end_time": "2020-12-11T15:24:30.127748",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-11T14:10:25.717032",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
